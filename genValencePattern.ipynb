{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### loading data now...\n",
      "# training_data\n",
      " - number of full-sentences: 14811\n",
      " - number of sentences: 33311 \n",
      "\n",
      "# test_data\n",
      " - number of full-sentences: 1863\n",
      " - number of sentences: 2793 \n",
      "\n",
      "# training_fe (for FE identification)\n",
      " - number of full-sentences: 4248\n",
      " - number of sentences: 14462 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import preprocessor\n",
    "import re\n",
    "from koreanframenet import kfn\n",
    "\n",
    "# loading DATA\n",
    "def load_data():\n",
    "    training, test, training_fe = preprocessor.load_data()\n",
    "    #result = training + test\n",
    "    result = training\n",
    "    return result\n",
    "\n",
    "koreanFN = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '이란은', '이란/NNG+은/JX', '이란은', 'NNG+JX', 'NNG+JX', '_', '_', '8', '8', 'NP_SBJ', 'NP_SBJ', '_', '_', 'S_speaker']\n",
      "['1', '화학', '화학/NNG', '화학', 'NNG', 'NNG', '_', '_', '2', '2', 'NP', 'NP', '_', '_', 'B_topic']\n",
      "['2', '시설과', '시설/NNG+과/JC', '시설과', 'NNG+JC', 'NNG+JC', '_', '_', '8', '8', 'NP_CNJ', 'NP_CNJ', '_', '_', 'I_topic']\n",
      "['3', '과거', '과거/NNG', '과거', 'NNG', 'NNG', '_', '_', '8', '8', 'NP_AJT', 'NP_AJT', '_', '_', 'I_topic']\n",
      "['4', '화학무기', '화학무기/NNG', '화학무기', 'NNG', 'NNG', '_', '_', '5', '5', 'NP', 'NP', '_', '_', 'I_topic']\n",
      "['5', '비축에', '비축/NNG+에/JKB', '비축에', 'NNG+JKB', 'NNG+JKB', '_', '_', '6', '6', 'NP_AJT', 'NP_AJT', '_', '_', 'I_topic']\n",
      "['6', '관한', '관하/VV+ㄴ/ETM', '관한', 'VV+ETM', 'VV+ETM', '_', '_', '7', '7', 'VP_MOD', 'VP_MOD', '_', '_', 'I_topic']\n",
      "['7', '선언서를', '선언서/NNG+를/JKO', '선언서를', 'NNG+JKO', 'NNG+JKO', '_', '_', '8', '8', 'NP_OBJ', 'NP_OBJ', '선언서.n', 'Statement', 'O']\n",
      "['8', '제출하였는데,', '제출하/VV+었/EP+는데/EC+,/SP', '제출하였는데,', 'VV+EP+EC+SP', 'VV+EP+EC+SP', '_', '_', '18', '18', 'VP', 'VP', '_', '_', 'O']\n",
      "['9', '이란은', '이란/NNG+은/JX', '이란은', 'NNG+JX', 'NNG+JX', '_', '_', '18', '18', 'NP_SBJ', 'NP_SBJ', '_', '_', 'O']\n",
      "['10', '화학무기', '화학무기/NNG', '화학무기', 'NNG', 'NNG', '_', '_', '11', '11', 'NP', 'NP', '_', '_', 'O']\n",
      "['11', '금지기구', '금지기구/NNG', '금지기구', 'NNG', 'NNG', '_', '_', '12', '12', 'NP', 'NP', '_', '_', 'O']\n",
      "['12', '조사관들이', '조사관들/NNG+이/JKS', '조사관들이', 'NNG+JKS', 'NNG+JKS', '_', '_', '13', '13', 'NP_SBJ', 'NP_SBJ', '_', '_', 'O']\n",
      "['13', '있는', '있/VA+는/ETM', '있는', 'VA+ETM', 'VA+ETM', '_', '_', '14', '14', 'VP_MOD', 'VP_MOD', '_', '_', 'O']\n",
      "['14', '곳에서', '곳/NNG+에서/JKB', '곳에서', 'NNG+JKB', 'NNG+JKB', '_', '_', '18', '18', 'NP_AJT', 'NP_AJT', '_', '_', 'O']\n",
      "['15', '화학무기', '화학무기/NNG', '화학무기', 'NNG', 'NNG', '_', '_', '16', '16', 'NP', 'NP', '_', '_', 'O']\n",
      "['16', '생산', '생산/NNG', '생산', 'NNG', 'NNG', '_', '_', '17', '17', 'NP', 'NP', '_', '_', 'O']\n",
      "['17', '장비를', '장비/NNG+를/JKO', '장비를', 'NNG+JKO', 'NNG+JKO', '_', '_', '18', '18', 'NP_OBJ', 'NP_OBJ', '_', '_', 'O']\n",
      "['18', '파괴하였고,', '파괴하/VV+었/EP+고/EC+,/SP', '파괴하였고,', 'VV+EP+EC+SP', 'VV+EP+EC+SP', '_', '_', '22', '22', 'VP', 'VP', '_', '_', 'O']\n",
      "['19', '화학', '화학/NNG', '화학', 'NNG', 'NNG', '_', '_', '20', '20', 'NP', 'NP', '_', '_', 'O']\n",
      "['20', '산업', '산업/NNG', '산업', 'NNG', 'NNG', '_', '_', '21', '21', 'NP', 'NP', '_', '_', 'O']\n",
      "['21', '시설들에', '시설들/NNG+에/JKB', '시설들에', 'NNG+JKB', 'NNG+JKB', '_', '_', '22', '22', 'NP_AJT', 'NP_AJT', '_', '_', 'O']\n",
      "['22', '대해', '대하/VV+어/EC', '대해', 'VV+EC', 'VV+EC', '_', '_', '28', '28', 'VP', 'VP', '_', '_', 'O']\n",
      "['23', '화학무기', '화학무기/NNG', '화학무기', 'NNG', 'NNG', '_', '_', '24', '24', 'NP', 'NP', '_', '_', 'O']\n",
      "['24', '금지기구의', '금지기구/NNG+의/JKG', '금지기구의', 'NNG+JKG', 'NNG+JKG', '_', '_', '25', '25', 'NP_MOD', 'NP_MOD', '_', '_', 'O']\n",
      "['25', '조사를', '조사/NNG+를/JKO', '조사를', 'NNG+JKO', 'NNG+JKO', '_', '_', '28', '28', 'NP_OBJ', 'NP_OBJ', '_', '_', 'O']\n",
      "['26', '수', '수/MM', '수', 'MM', 'MM', '_', '_', '27', '27', 'DP', 'DP', '_', '_', 'O']\n",
      "['27', '차례', '차례/NNG', '차례', 'NNG', 'NNG', '_', '_', '28', '28', 'NP_AJT', 'NP_AJT', '_', '_', 'O']\n",
      "['28', '받았다.', '받/VV+었/EP+다/EF+./SF', '받았다.', 'VV+EP+EF+SF', 'VV+EP+EF+SF', '_', '_', '-1', '-1', 'VP', 'VP', '_', '_', 'O']\n"
     ]
    }
   ],
   "source": [
    "def dummy():\n",
    "    for i in koreanFN[0]:\n",
    "        print(i)\n",
    "dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for a given sentence list, it identifies 'target' and 'its frame'\n",
    "def get_target(sent_list):\n",
    "    token_list = []\n",
    "    frame = 'None'\n",
    "    for i in sent_list:\n",
    "        #print(i)\n",
    "        if i[12] != '_':\n",
    "            token_list.append(i[1])\n",
    "            frame = i[13]\n",
    "    target = ' '.join(token_list)\n",
    "    spc = [',','.','!','?']\n",
    "    if len(target) >1:\n",
    "        if target[-1] in spc:\n",
    "            target = re.sub('[,.?!]', '', target)\n",
    "    return target, frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for a given sentence list, it identifies an ID of 'LU'\n",
    "def get_lu_id(sent_list):\n",
    "    target, frame = get_target(sent_list)\n",
    "    print('target:', target, 'frame:', frame)\n",
    "    lu_id = kfn.surface_to_lu_id(target, frame)\n",
    "    \n",
    "    return lu_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CoNLL format의 문장 리스트에 대해, valence pattern을 생성하는 함수\n",
    "def getValencePattern(sent_list):\n",
    "    result = []\n",
    "    fes = []\n",
    "    for token in sent_list:\n",
    "        if token[14] != 'O':\n",
    "            fe = token[14].split('_')[1]\n",
    "            fes.append(fe)\n",
    "    fes = list(set(fes))\n",
    "    for fe in fes:\n",
    "        pos_seq = []\n",
    "        pt_seq = []\n",
    "        for token in sent_list:\n",
    "            if token[14] != 'O':\n",
    "                fe_in_sent = token[14].split('_')[1]\n",
    "            else:\n",
    "                fe_in_sent = token[14]\n",
    "            if fe == fe_in_sent:\n",
    "                # 각 argument 에 대해서 패턴 생성\n",
    "                pos_seq.append(token[4])\n",
    "                pt_seq.append(token[9])\n",
    "                pt = token[9]\n",
    "                pos = token[4]\n",
    "                if 'J' in pos:\n",
    "                    suffix = token[2].split('+')[-1]\n",
    "                    suffix_pos = token[4].split('+')[-1]\n",
    "                elif 'NN' in pos:\n",
    "                    suffix = ''\n",
    "                    suffix_pos = ''\n",
    "                else:\n",
    "                    suffix = token[1]+'/'+token[4]\n",
    "                    suffix_pos = token[4]                    \n",
    "        valenceUnit = {}\n",
    "        valenceUnit['FE'] = fe\n",
    "        valenceUnit['PT'] = pt\n",
    "        valenceUnit['suffix'] = suffix\n",
    "        valenceUnit['suffix_pos'] = suffix_pos\n",
    "        valenceUnit['pos_sequence'] = pos_seq\n",
    "        valenceUnit['pt_sequence'] = pt_seq\n",
    "        result.append(valenceUnit)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def genData():\n",
    "    result = []\n",
    "    # koreanFN = trainign data in CONLL format\n",
    "    for sent_list in koreanFN:\n",
    "        each_lu = {}\n",
    "        lu_id = get_lu_id(sent_list)\n",
    "        lu = kfn.lu(lu_id)\n",
    "        each_lu['lu_id'] = lu['lu_id']\n",
    "        # by this process, 'LU' is identified in training data\n",
    "        isIn = False\n",
    "        for i in result:\n",
    "            if i['lu_id'] == lu_id:\n",
    "                each_lu = i\n",
    "                vp_list = each_lu['valencePatterns']\n",
    "                # valence pattern 을 생성하는 함수 호출\n",
    "                vp = getValencePattern(sent_list)\n",
    "                vp_list = vp_list + vp\n",
    "                each_lu['valencePatterns'] = vp_list\n",
    "                i = each_lu\n",
    "                isIn = True\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        if isIn == True:\n",
    "            pass\n",
    "            # result list 에 대해 중복 제거하기 위함\n",
    "        else:\n",
    "            each_lu['lu'] = lu['lu']\n",
    "            each_lu['surface_forms'] = lu['surface_forms']\n",
    "            each_lu['lexeme'] = lu['lexeme']\n",
    "            vp_list = []\n",
    "            # valence pattern 을 생성하는 함수 호출\n",
    "            vp = getValencePattern(sent_list)\n",
    "            vp_list = vp_list + vp\n",
    "            each_lu['valencePatterns'] = vp_list        \n",
    "            result.append(each_lu)\n",
    "        \n",
    "        print(lu['lu'])\n",
    "        print(each_lu)\n",
    "    # SAVE Valence Pattern to FILE\n",
    "    with open('./valencePattern_0702.json','w') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "#genData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lexeme': '선언서', 'lu_id': 1, 'surface_forms': ['선언서를'], 'lu': '선언서.n.Statement', 'valencePatterns': [{'pt_sequence': ['8'], 'FE': 'speaker', 'pos_sequence': ['NNG+JX'], 'PT': '8', 'suffix': '은/JX', 'suffix_pos': 'JX'}, {'pt_sequence': ['2', '8', '8', '5', '6', '7'], 'FE': 'topic', 'pos_sequence': ['NNG', 'NNG+JC', 'NNG', 'NNG', 'NNG+JKB', 'VV+ETM'], 'PT': '7', 'suffix': '관한/VV+ETM', 'suffix_pos': 'VV+ETM'}]}\n",
      "10359\n",
      "3210\n"
     ]
    }
   ],
   "source": [
    "def test_data():\n",
    "    with open('./valencePattern_0702.json','r') as f:\n",
    "        d = json.load(f)\n",
    "    for i in d:\n",
    "        print(i)\n",
    "        break\n",
    "    count = 0\n",
    "    print(len(d))\n",
    "    for i in d:\n",
    "        vp = i['valencePatterns']\n",
    "        if len(vp) > 0:\n",
    "            count = count+1\n",
    "    print(count)\n",
    "test_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
