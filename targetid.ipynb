{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: CoNLL2009-based list (output of preprocessor.py)\n",
    "\n",
    "from koreanframenet import kfn\n",
    "import preprocessor\n",
    "import re\n",
    "from src import etri\n",
    "import posChanger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training_data\n",
      " - number of sentences: 8\n",
      " - number of annotations: 39 \n",
      "\n",
      "# test_data\n",
      " - number of sentences: 3\n",
      " - number of annotations: 16 \n",
      "\n",
      "# dev_data\n",
      " - number of sentences: 0\n",
      " - number of annotations: 0 \n",
      "\n",
      "# exemplar data (from sejong)\n",
      " - number of sentences: 10967\n",
      " - number of annotations: 10967 \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_identification_surfaceform(sent_list):\n",
    "    result = []\n",
    "    frame = 'None'\n",
    "    for i in sent_list:\n",
    "        #print(i[0], i[2], i[3])\n",
    "        lu1, lu2 = [],[]\n",
    "        #print(i)\n",
    "        lus =[]\n",
    "        lex = i[2].split('+')[0].split('/')[0]\n",
    "        pos = i[2].split('+')[0].split('/')[1]\n",
    "        pos = posChanger.posChanger(pos)\n",
    "        lemma = lex+'.'+pos\n",
    "        lu1 = kfn.lus_by_lemma(lemma)\n",
    "        #print(lu1)\n",
    "        \n",
    "        surfaceform = i[1]\n",
    "        spc = [',','.','!','?']\n",
    "        if len(surfaceform) > 1:\n",
    "            if surfaceform[-1] in spc:\n",
    "                surfaceform = re.sub('[,.?!]', '', surfaceform)\n",
    "        lu2 = kfn.lus_by_surfaceform(surfaceform)\n",
    "        lus = lu1+lu2\n",
    "        lus = list(set(lus))\n",
    "        \n",
    "        pos = i[4].split('+')[0]\n",
    "        pos = posChanger.posChanger(pos)\n",
    "        lu_candis = []\n",
    "        if len(lus) > 0:\n",
    "            for lc in lus:\n",
    "                lu_pos = lc.split('.')[1]\n",
    "                #print('pos', pos, lu_pos)\n",
    "                if pos == lu_pos:\n",
    "                    lu_candi_list = lc.split('.')[:-1]\n",
    "                    lu_candi = '.'.join(lu_candi_list)\n",
    "                    lu_candis.append(lu_candi)\n",
    "                    #print(lu_candi)\n",
    "                    #if surfaceform[0] == lu_candi[0]:\n",
    "                        #lu_candis.append(lu_candi)\n",
    "        lu_candis = list(set(lu_candis))\n",
    "#         print(lu_candis)\n",
    "        if len(lu_candis) > 0:\n",
    "            lu = False\n",
    "            max = 0\n",
    "            for j in lu_candis:\n",
    "                lexu_list = kfn.lus_by_lu(j)\n",
    "                for k in lexu_list:\n",
    "                    count = len(k['ko_annotation_id'])\n",
    "                    if count > max:\n",
    "                        lu = j\n",
    "                        max = count                \n",
    "            lu_dict = {}\n",
    "            lu_dict['token_id'] = i[0]\n",
    "            lu_dict['lu'] = lu\n",
    "            lu_with_frame = []\n",
    "            for j in lus:\n",
    "                lexu = j.split('.')[0] + '.' + j.split('.')[1]\n",
    "                if lexu == lu:\n",
    "                    lu_with_frame.append(j)\n",
    "            lu_dict['lu_with_frame'] = lu_with_frame\n",
    "            if lu != False:\n",
    "                result.append(lu_dict)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy():\n",
    "    st = '선언서를'\n",
    "    d = kfn.lus_by_surfaceform(st)\n",
    "    print(d)\n",
    "#dummy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_identifier(sent_list, model):\n",
    "    if model == 'baseline':\n",
    "        targets = target_identification_surfaceform(sent_list)\n",
    "    else:\n",
    "        targets = target_identification_surfaceform(sent_list)\n",
    "    result = []\n",
    "    token_list = sent_list\n",
    "    for i in range(len(targets)):\n",
    "        new_token_list = []\n",
    "        for token in token_list:\n",
    "            new_token = token\n",
    "            if len(new_token) > 12:\n",
    "                new_token = token[:12]\n",
    "            tokid = token[0]\n",
    "            if tokid == targets[i]['token_id']:\n",
    "                new_token.append(targets[i]['lu'])\n",
    "            else:\n",
    "                new_token.append('_')\n",
    "            new_token_list.append(new_token)\n",
    "        result.append(new_token_list)\n",
    "    if len(result) == 0:\n",
    "        new_token_list = []\n",
    "        for token in token_list:\n",
    "            new_token = token[:12]\n",
    "            new_token.append('_')\n",
    "            new_token_list.append(new_token)\n",
    "        result.append(new_token_list)\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '나는', '나/NP+는/JX', '나는', 'NP+JX', 'NP+JX', '_', '_', 2, 2, 'NP_SBJ', 'NP_SBJ', '_']\n",
      "[1, '밥을', '밥/NNG+을/JKO', '밥을', 'NNG+JKO', 'NNG+JKO', '_', '_', 2, 2, 'NP_OBJ', 'NP_OBJ', '_']\n",
      "[2, '먹고', '먹/VV+고/EC', '먹고', 'VV+EC', 'VV+EC', '_', '_', 4, 4, 'VP', 'VP', '먹다.v']\n",
      "[3, '학교에', '학교/NNG+에/JKB', '학교에', 'NNG+JKB', 'NNG+JKB', '_', '_', 4, 4, 'NP_AJT', 'NP_AJT', '_']\n",
      "[4, '갔다', '가/VV+었/EP+다/EF', '갔다', 'VV+EP+EF', 'VV+EP+EF', '_', '_', -1, -1, 'VP', 'VP', '_']\n",
      "\n",
      "[0, '나는', '나/NP+는/JX', '나는', 'NP+JX', 'NP+JX', '_', '_', 2, 2, 'NP_SBJ', 'NP_SBJ', '_']\n",
      "[1, '밥을', '밥/NNG+을/JKO', '밥을', 'NNG+JKO', 'NNG+JKO', '_', '_', 2, 2, 'NP_OBJ', 'NP_OBJ', '_']\n",
      "[2, '먹고', '먹/VV+고/EC', '먹고', 'VV+EC', 'VV+EC', '_', '_', 4, 4, 'VP', 'VP', '_']\n",
      "[3, '학교에', '학교/NNG+에/JKB', '학교에', 'NNG+JKB', 'NNG+JKB', '_', '_', 4, 4, 'NP_AJT', 'NP_AJT', '학교.n']\n",
      "[4, '갔다', '가/VV+었/EP+다/EF', '갔다', 'VV+EP+EF', 'VV+EP+EF', '_', '_', -1, -1, 'VP', 'VP', '_']\n",
      "\n",
      "[0, '나는', '나/NP+는/JX', '나는', 'NP+JX', 'NP+JX', '_', '_', 2, 2, 'NP_SBJ', 'NP_SBJ', '_']\n",
      "[1, '밥을', '밥/NNG+을/JKO', '밥을', 'NNG+JKO', 'NNG+JKO', '_', '_', 2, 2, 'NP_OBJ', 'NP_OBJ', '_']\n",
      "[2, '먹고', '먹/VV+고/EC', '먹고', 'VV+EC', 'VV+EC', '_', '_', 4, 4, 'VP', 'VP', '_']\n",
      "[3, '학교에', '학교/NNG+에/JKB', '학교에', 'NNG+JKB', 'NNG+JKB', '_', '_', 4, 4, 'NP_AJT', 'NP_AJT', '_']\n",
      "[4, '갔다', '가/VV+었/EP+다/EF', '갔다', 'VV+EP+EF', 'VV+EP+EF', '_', '_', -1, -1, 'VP', 'VP', '가다.v']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    sent = '나는 밥을 먹고 학교에 갔다'\n",
    "    conll = etri.getETRI_CoNLL2009(sent)\n",
    "    #targets = target_identifier(conll)\n",
    "#    for i in sent_list:\n",
    "#        print(i[0], i[2])\n",
    "\n",
    "    #targets = target_identification_surfaceform(sent_list)\n",
    "    result = target_identifier(conll, 'baseline')\n",
    "    for i in result:\n",
    "        for j in i:\n",
    "            print(j)\n",
    "        print('')\n",
    "#test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
