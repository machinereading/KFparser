{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koreanframenet import kfn\n",
    "import json\n",
    "from src import etri\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### load KFN ###\n"
     ]
    }
   ],
   "source": [
    "def load_kfn():\n",
    "    dir_path = os.getcwd()\n",
    "    with open(dir_path+'/koreanframenet/resource/KFN_lus.json', 'r') as f:\n",
    "        kolu = json.load(f)\n",
    "    with open(dir_path+'/koreanframenet/resource/KFN_annotations.json','r') as f:\n",
    "        koanno = json.load(f)\n",
    "    print('### load KFN ###')\n",
    "    return kolu, koanno\n",
    "kolu, koanno = load_kfn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Generate Sentence List of TRN, TST, and DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KOREAN FRAMENET DATA (CoNLL format) GENERATION\n",
      "_____________________\n",
      "\n",
      "...shuffle Korean FrameNet full-text annotation sentences...\n",
      "training data: \t3625 sents\n",
      "dev data:      \t200  sents\n",
      "test data:     \t1250 sents\n"
     ]
    }
   ],
   "source": [
    "def gen_list():\n",
    "    sent_ids = []\n",
    "    for i in koanno:\n",
    "        sent_id = i['text']['sent_id']\n",
    "        sent_ids.append(sent_id)\n",
    "    random.shuffle(sent_ids)\n",
    "    \n",
    "    tst = sent_ids[:1250]\n",
    "    dev = sent_ids[1250:1450]\n",
    "    trn = sent_ids[1400:]\n",
    "\n",
    "    result = {}\n",
    "    result['trn'] = trn\n",
    "    result['tst'] = tst\n",
    "    result['dev'] = dev\n",
    "    #result['dev'] = dev\n",
    "    sys.stderr.write(\"\\nKOREAN FRAMENET DATA (CoNLL format) GENERATION\\n_____________________\\n\")\n",
    "    sys.stderr.write(\"\\n...shuffle Korean FrameNet full-text annotation sentences...\\n\")\n",
    "    sys.stderr.write(\"training data: \\t\" + str(len(trn)) + ' sents\\n')\n",
    "    sys.stderr.write(\"dev data:      \\t\" + str(len(dev)) + '  sents\\n')\n",
    "    sys.stderr.write(\"test data:     \\t\" + str(len(tst)) + ' sents\\n')\n",
    "    return result\n",
    "sent_list = gen_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Generate CoNLL for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eid(span, ori_text):\n",
    "    text = ' '.join(ori_text.split())\n",
    "    sent_list = text.split(' ')\n",
    "    #print(sent_list)\n",
    "    b,e = int(span['begin']), int(span['end'])\n",
    "    n = 0\n",
    "    k = 0\n",
    "    ori_text_list = ori_text.split(' ')\n",
    "    #print(ori_text_list)\n",
    "    for i in ori_text_list:\n",
    "        if i == '':\n",
    "            k = k+1\n",
    "    #print('k:',k)\n",
    "    e_num = 0\n",
    "    e_list = []\n",
    "    for eojeol in sent_list:\n",
    "        if eojeol == '':\n",
    "            pass\n",
    "        else:\n",
    "            eojeol_begin_offset = n\n",
    "            eojeol_end_offset = n+len(eojeol)\n",
    "            n = eojeol_end_offset+1\n",
    "            t = (eojeol_begin_offset, eojeol_end_offset, e_num, eojeol)\n",
    "            e_list.append(t)\n",
    "            e_num = e_num +1\n",
    "    begin, end = 0,0\n",
    "    for i in e_list:\n",
    "        if b <= i[0]+k or (b >=i[0] and e <= i[1]+k):\n",
    "            begin = i[2]\n",
    "            break\n",
    "    for i in e_list:\n",
    "        if e <= i[1]+k:\n",
    "            end = i[2]\n",
    "            break\n",
    "    return begin, end\n",
    "\n",
    "def get_lu_frame(anno_id):\n",
    "    for i in kolu:\n",
    "        if type(anno_id) == str:\n",
    "            if anno_id in i['sejong_annotation_id']:\n",
    "                lu_name = i['lu']\n",
    "                break\n",
    "        else:\n",
    "            if anno_id in i['ko_annotation_id']:\n",
    "                lu_name = i['lu']\n",
    "                break\n",
    "    lu_list = lu_name.split('.')\n",
    "    lu = lu_list[0]+'.'+lu_list[1]\n",
    "    frame = lu_list[2]\n",
    "    return lu, frame\n",
    "\n",
    "def getBIO_list(sent_list):\n",
    "    result = []\n",
    "    fe_list = []\n",
    "    for i in range(len(sent_list)):\n",
    "        fe = sent_list[i][14].lower()\n",
    "        fe_list.append(fe)\n",
    "    for i in range(len(sent_list)):\n",
    "        fe = sent_list[i][14].lower()\n",
    "        if i == 0:\n",
    "            if fe == '_':\n",
    "                fe = 'O'\n",
    "            else:\n",
    "                try:\n",
    "                    if fe == fe_list[i+1]:\n",
    "                        fe = 'B_'+fe\n",
    "                    else:\n",
    "                        fe = 'S_'+fe\n",
    "                except KeyboardInterrupt:\n",
    "                    raise\n",
    "                except:\n",
    "                    fe = 'S_'+fe\n",
    "        else:\n",
    "            if fe == '_':\n",
    "                fe = 'O'\n",
    "            else:\n",
    "                if fe != fe_list[i-1]:\n",
    "                    try:\n",
    "                        if fe == fe_list[i+1]:\n",
    "                            fe = 'B_'+fe\n",
    "                        else:\n",
    "                            fe = 'S_'+fe\n",
    "                    except KeyboardInterrupt:\n",
    "                        raise\n",
    "                    except:\n",
    "                        fe = 'S_'+fe\n",
    "                else:\n",
    "                    fe = 'I_'+fe\n",
    "        result.append(fe)\n",
    "    for i in range(len(sent_list)):\n",
    "        sent_list[i][14] = result[i]\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genCoNLLdata(anno):\n",
    "    result = []\n",
    "    sent_id = anno['sent_id'] \n",
    "    ori_text = anno['ko_text']\n",
    "    denos = anno['annotations']\n",
    "    text = ' '.join(ori_text.split())\n",
    "\n",
    "    for deno in denos:\n",
    "        try:\n",
    "            conll = etri.getETRI_CoNLL2009(ori_text)\n",
    "            anno_id = deno['ko_annotation_id']            \n",
    "            try:\n",
    "                lu, frame = get_lu_frame(anno_id)\n",
    "                for d in deno['denotations']:\n",
    "                    span = d['span']\n",
    "                    if d['obj'] == 'target':\n",
    "                        begin, end = get_eid(span, ori_text)\n",
    "                        for token in conll:\n",
    "                            tid = token[0]\n",
    "                            if tid >= begin and tid <= end:\n",
    "                                token.append(lu)\n",
    "                                token.append(frame)\n",
    "                            else:\n",
    "                                token.append('_')\n",
    "                                token.append('_')\n",
    "                for d in deno['denotations']:\n",
    "                    fe = d['obj']\n",
    "                    span = d['span']\n",
    "                    if fe != 'target':\n",
    "                        begin, end = get_eid(span, ori_text)\n",
    "                        for token in conll:\n",
    "                            tid = token[0]\n",
    "                            if tid >= begin and tid <= end:\n",
    "                                token.append(fe)\n",
    "                for token in conll:\n",
    "                    if len(token) == 14:\n",
    "                        token.append('_')\n",
    "                conll = getBIO_list(conll)\n",
    "                result.append(conll)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except:\n",
    "                #print('err2',anno_id)\n",
    "                pass\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            pass\n",
    "            #print('err1',sent_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Write Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_sejong():\n",
    "#     with open('./koreanframenet/resource/KFN_annotations_from_sejong.json','r') as f:\n",
    "#         sejong = json.load(f)\n",
    "#     return sejong\n",
    "# sejong = load_sejong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training_data\n",
      " - number of sentences: 8\n",
      " - number of annotations: 42 \n",
      "\n",
      "# test_data\n",
      " - number of sentences: 3\n",
      " - number of annotations: 13 \n",
      "\n",
      "# dev_data\n",
      " - number of sentences: 0\n",
      " - number of annotations: 0 \n",
      "\n",
      "# exemplar data (from sejong)\n",
      " - number of sentences: 10967\n",
      " - number of annotations: 10967 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def write_data():\n",
    "    sys.stderr.write(\"\\n...converting data to CoNLL 2009 format...\\n\")\n",
    "    dir_path = os.getcwd()\n",
    "    dev = sent_list['dev']\n",
    "    tst = sent_list['tst']\n",
    "    trn = sent_list['trn']\n",
    "    trn_file = open(dir_path+'/koreanframenet/data/training.tsv', 'w')\n",
    "    dev_file = open(dir_path+'/koreanframenet/data/dev.tsv', 'w')\n",
    "    tst_file = open(dir_path+'/koreanframenet/data/test.tsv', 'w')\n",
    "\n",
    "#     for s in sejong:\n",
    "#         for a in s['annotations']:\n",
    "#             anno = {}\n",
    "#             anno['sent_id'] = a['ko_annotation_id']\n",
    "#             anno['ko_text'] = a['text']\n",
    "#             anno['annotations'] = [a]\n",
    "\n",
    "#             conlls = genCoNLLdata(anno)\n",
    "#             for conll in conlls:\n",
    "#                 add = False\n",
    "#                 for t in conll:\n",
    "#                     if t[12] != '_':\n",
    "#                         add = True\n",
    "#                 if add == True:\n",
    "#                     with open('./koreanframenet/data/exemplar.tsv', 'a') as f:\n",
    "#                         sent_id = str(anno['sent_id'])\n",
    "#                         sent = anno['ko_text']\n",
    "#                         f.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "#                         f.write(\"#text:\"+sent+\"\\n\")\n",
    "#                         for token in conll:\n",
    "#                             line = '\\t'.join(map(str,token))\n",
    "#                             f.write(line+\"\\n\")\n",
    "#                         f.write('\\n')  \n",
    "    for i in koanno:\n",
    "        s_id = i['text']['sent_id']\n",
    "        if s_id in tst:\n",
    "            anno = {}\n",
    "            anno['sent_id'] = i['text']['sent_id']\n",
    "            anno['ko_text'] = i['text']['ko_text']\n",
    "            anno['annotations'] = i['frameAnnotation']['ko_annotations']\n",
    "            conlls = genCoNLLdata(anno)\n",
    "            for conll in conlls:\n",
    "                add = False\n",
    "                for t in conll:\n",
    "                    if t[12] != '_':\n",
    "                        add = True\n",
    "                for t in conll:\n",
    "                    if t[14] in ['B_x', 'I_x', 'S_x']:\n",
    "                        add = False\n",
    "                if add == True:\n",
    "                    sent_id = str(anno['sent_id'])\n",
    "                    sent = anno['ko_text']\n",
    "                    tst_file.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "                    tst_file.write(\"#text:\"+sent+\"\\n\")\n",
    "                    for token in conll:\n",
    "                        line = '\\t'.join(map(str,token))\n",
    "                        tst_file.write(line+\"\\n\")\n",
    "                    tst_file.write('\\n')\n",
    "        elif s_id in dev:\n",
    "            anno = {}\n",
    "            anno['sent_id'] = i['text']['sent_id']\n",
    "            anno['ko_text'] = i['text']['ko_text']\n",
    "            anno['annotations'] = i['frameAnnotation']['ko_annotations']\n",
    "            conlls = genCoNLLdata(anno)\n",
    "            for conll in conlls:\n",
    "                add = False\n",
    "                for t in conll:\n",
    "                    if t[12] != '_':\n",
    "                        add = True\n",
    "                for t in conll:\n",
    "                    if t[14] in ['B_x', 'I_x', 'S_x']:\n",
    "                        add = False\n",
    "                if add == True:\n",
    "                    sent_id = str(anno['sent_id'])\n",
    "                    sent = anno['ko_text']\n",
    "                    dev_file.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "                    dev_file.write(\"#text:\"+sent+\"\\n\")\n",
    "                    for token in conll:\n",
    "                        line = '\\t'.join(map(str,token))\n",
    "                        dev_file.write(line+\"\\n\")\n",
    "                    dev_file.write('\\n')\n",
    "        else:\n",
    "            anno = {}\n",
    "            anno['sent_id'] = i['text']['sent_id']\n",
    "            anno['ko_text'] = i['text']['ko_text']\n",
    "            anno['annotations'] = i['frameAnnotation']['ko_annotations']\n",
    "\n",
    "            conlls = genCoNLLdata(anno)\n",
    "            for conll in conlls:\n",
    "                add = False\n",
    "                for t in conll:\n",
    "                    if t[12] != '_':\n",
    "                        add = True\n",
    "                for t in conll:\n",
    "                    if t[14] in ['B_x', 'I_x', 'S_x']:\n",
    "                        add = False\n",
    "                if add == True:\n",
    "                    sent_id = str(anno['sent_id'])\n",
    "                    sent = anno['ko_text']\n",
    "                    trn_file.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "                    trn_file.write(\"#text:\"+sent+\"\\n\")\n",
    "                    for token in conll:\n",
    "                        line = '\\t'.join(map(str,token))\n",
    "                        trn_file.write(line+\"\\n\")\n",
    "                    trn_file.write('\\n')\n",
    "    trn_file.close()\n",
    "    tst_file.close()\n",
    "    dev_file.close()\n",
    "    preprocessor.data_stat()\n",
    "write_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
