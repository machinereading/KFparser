{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from koreanframenet import kfn\n",
    "import json\n",
    "import etri\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### load KFN ###\n"
     ]
    }
   ],
   "source": [
    "def load_kfn():\n",
    "    with open('./koreanframenet/resource/KFN_lus.json', 'r') as f:\n",
    "        kolu = json.load(f)\n",
    "    with open('./koreanframenet/resource/KFN_annotations.json','r') as f:\n",
    "        koanno = json.load(f)\n",
    "    print('### load KFN ###')\n",
    "    return kolu, koanno\n",
    "kolu, koanno = load_kfn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Generate Sentence List of TRN, TST, and DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525 3500\n"
     ]
    }
   ],
   "source": [
    "def gen_list():\n",
    "    sent_ids = []\n",
    "    for i in koanno:\n",
    "        sent_id = i['text']['sent_id']\n",
    "        sent_ids.append(sent_id)\n",
    "    random.shuffle(sent_ids)\n",
    "    \n",
    "    tst = sent_ids[:3500]\n",
    "    trn = sent_ids[3500:]\n",
    "\n",
    "    result = {}\n",
    "    result['trn'] = trn\n",
    "    result['tst'] = tst\n",
    "    #result['dev'] = dev\n",
    "    print(len(trn), len(tst))\n",
    "    return result\n",
    "sent_list = gen_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn is done\n",
      "tst is done\n"
     ]
    }
   ],
   "source": [
    "def get_luid(anno_id):\n",
    "    luid = False\n",
    "    for lu in kolu:\n",
    "        if anno_id in lu['ko_annotation_id']:\n",
    "            luid = lu['lu_id']\n",
    "            #print(luid)\n",
    "            break\n",
    "    return luid\n",
    "\n",
    "def get_fes(deno):\n",
    "    fes = []\n",
    "    for d in deno:\n",
    "        if d['obj'] != 'target':\n",
    "            fe = d['obj'].lower()\n",
    "            fes.append(fe)\n",
    "    fes = list(set(fes))\n",
    "    return fes \n",
    "\n",
    "def get_lus(data):\n",
    "    result = []\n",
    "    for i in koanno:\n",
    "        sent_id = i['text']['sent_id']\n",
    "        lu_list = []\n",
    "        if sent_id in data:\n",
    "            annos = i['frameAnnotation']['ko_annotations']\n",
    "            for a in annos:\n",
    "                anno_id = a['ko_annotation_id']\n",
    "                lu = get_luid(anno_id)\n",
    "                deno = a['denotations']\n",
    "                lu_fes = get_fes(deno)\n",
    "                if lu != False:\n",
    "                    lu_dic = {}\n",
    "                    lu_dic['luid'] = lu\n",
    "                    lu_dic['fes'] = lu_fes\n",
    "                    lu_list.append(lu_dic)\n",
    "                    \n",
    "            d = {}\n",
    "            d['sent_id'] = sent_id\n",
    "            d['lus'] = lu_list\n",
    "            result.append(d)\n",
    "    #lus = list(set(lus))\n",
    "    return result\n",
    "\n",
    "def gen_lus():\n",
    "    trn, tst= sent_list['trn'], sent_list['tst']\n",
    "    d = {}\n",
    "    d['trn'] = get_lus(trn)\n",
    "    print('trn is done')\n",
    "    d['tst'] = get_lus(tst)\n",
    "    print('tst is done')\n",
    "#     d['dev'] = get_lus(dev)\n",
    "#     print('dev is done')\n",
    "    \n",
    "    with open('./data/data_lus.json','w') as f:\n",
    "        json.dump(d, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#gen_lus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3973 952 100\n",
      "1002 6157 3500\n"
     ]
    }
   ],
   "source": [
    "with open('./data/data_lus.json','r') as f:\n",
    "    data_lus = json.load(f)\n",
    "\n",
    "def check_lus():\n",
    "    lus_in_trn = []\n",
    "    for trn_sent in data_lus['trn']:\n",
    "        for i in trn_sent['lus']:\n",
    "            luid, fes = i['luid'], i['fes']\n",
    "            tu = (luid, fes)\n",
    "            lus_in_trn.append(tu)        \n",
    "\n",
    "    sent_list = []\n",
    "    sent_count, anno_count = 0,0 \n",
    "    for tst_sent in data_lus['tst']:\n",
    "        count = 0\n",
    "        sent_id = tst_sent['sent_id']\n",
    "        for i in tst_sent['lus']:\n",
    "            luid, fes = i['luid'], i['fes']\n",
    "            check = False\n",
    "            for j in lus_in_trn:\n",
    "                if luid == j[0]:\n",
    "                    check_list = []\n",
    "                    for fe in fes:\n",
    "                        if fe in j[1]:\n",
    "                            check_list.append('t')\n",
    "                    if len(check_list) == len(fes):\n",
    "                        check = True\n",
    "                        #anno_count += 1\n",
    "                        break\n",
    "            if check == True:\n",
    "                anno_count += 1\n",
    "                count += 1\n",
    "            \n",
    "        if count == len(tst_sent['lus']):\n",
    "            sent_count += 1\n",
    "            sent_list.append(sent_id)\n",
    "    \n",
    "    random.shuffle(sent_list)\n",
    "    \n",
    "    dev = sent_list[:50]\n",
    "    tst = sent_list[50:]\n",
    "    trn = []\n",
    "    for i in koanno:\n",
    "        sent_id = i['text']['sent_id']\n",
    "        if sent_id not in tst:\n",
    "            if sent_id not in dev:\n",
    "                trn.append(sent_id)\n",
    "    dev = dev + trn[:50]\n",
    "    trn = trn[50:]\n",
    "    print(len(trn), len(tst), len(dev))\n",
    "    \n",
    "    d = {}\n",
    "    d['trn'] = trn\n",
    "    d['tst'] = tst\n",
    "    d['dev'] = dev\n",
    "    \n",
    "        \n",
    "    print(sent_count, anno_count, len(data_lus['tst']))\n",
    "    with open('./data/data_sent_list.json','w') as f:\n",
    "        json.dump(d, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "#check_lus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Generate CoNLL for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_eid(span, ori_text):\n",
    "    text = ' '.join(ori_text.split())\n",
    "    sent_list = text.split(' ')\n",
    "    #print(sent_list)\n",
    "    b,e = int(span['begin']), int(span['end'])\n",
    "    n = 0\n",
    "    k = 0\n",
    "    ori_text_list = ori_text.split(' ')\n",
    "    #print(ori_text_list)\n",
    "    for i in ori_text_list:\n",
    "        if i == '':\n",
    "            k = k+1\n",
    "    #print('k:',k)\n",
    "    e_num = 0\n",
    "    e_list = []\n",
    "    for eojeol in sent_list:\n",
    "        if eojeol == '':\n",
    "            pass\n",
    "        else:\n",
    "            eojeol_begin_offset = n\n",
    "            eojeol_end_offset = n+len(eojeol)\n",
    "            n = eojeol_end_offset+1\n",
    "            t = (eojeol_begin_offset, eojeol_end_offset, e_num, eojeol)\n",
    "            e_list.append(t)\n",
    "            e_num = e_num +1\n",
    "    begin, end = 0,0\n",
    "    for i in e_list:\n",
    "        if b <= i[0]+k or (b >=i[0] and e <= i[1]+k):\n",
    "            begin = i[2]\n",
    "            break\n",
    "    for i in e_list:\n",
    "        if e <= i[1]+k:\n",
    "            end = i[2]\n",
    "            break\n",
    "    return begin, end\n",
    "\n",
    "def get_lu_frame(anno_id):\n",
    "    for i in kolu:\n",
    "        if type(anno_id) == str:\n",
    "            if anno_id in i['sejong_annotation_id']:\n",
    "                lu_name = i['lu']\n",
    "                break\n",
    "        else:\n",
    "            if anno_id in i['ko_annotation_id']:\n",
    "                lu_name = i['lu']\n",
    "                break\n",
    "    lu_list = lu_name.split('.')\n",
    "    lu = lu_list[0]+'.'+lu_list[1]\n",
    "    frame = lu_list[2]\n",
    "    return lu, frame\n",
    "\n",
    "def getBIO_list(sent_list):\n",
    "    result = []\n",
    "    fe_list = []\n",
    "    for i in range(len(sent_list)):\n",
    "        fe = sent_list[i][14].lower()\n",
    "        fe_list.append(fe)\n",
    "    for i in range(len(sent_list)):\n",
    "        fe = sent_list[i][14]\n",
    "        if i == 0:\n",
    "            if fe == '_':\n",
    "                fe = 'O'\n",
    "            else:\n",
    "                try:\n",
    "                    if fe == fe_list[i+1]:\n",
    "                        fe = 'B_'+fe\n",
    "                    else:\n",
    "                        fe = 'S_'+fe\n",
    "                except KeyboardInterrupt:\n",
    "                    raise\n",
    "                except:\n",
    "                    fe = 'S_'+fe\n",
    "        else:\n",
    "            if fe == '_':\n",
    "                fe = 'O'\n",
    "            else:\n",
    "                if fe != fe_list[i-1]:\n",
    "                    try:\n",
    "                        if fe == fe_list[i+1]:\n",
    "                            fe = 'B_'+fe\n",
    "                        else:\n",
    "                            fe = 'S_'+fe\n",
    "                    except KeyboardInterrupt:\n",
    "                        raise\n",
    "                    except:\n",
    "                        fe = 'S_'+fe\n",
    "                else:\n",
    "                    fe = 'I_'+fe\n",
    "        result.append(fe)\n",
    "    for i in range(len(sent_list)):\n",
    "        sent_list[i][14] = result[i]\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genCoNLLdata(anno):\n",
    "    result = []\n",
    "    sent_id = anno['sent_id'] \n",
    "    ori_text = anno['ko_text']\n",
    "    denos = anno['annotations']\n",
    "    text = ' '.join(ori_text.split())\n",
    "\n",
    "    for deno in denos:\n",
    "        try:\n",
    "            conll = etri.getETRI_CoNLL2009(ori_text)\n",
    "            anno_id = deno['ko_annotation_id']            \n",
    "            try:\n",
    "                lu, frame = get_lu_frame(anno_id)\n",
    "                for d in deno['denotations']:\n",
    "                    span = d['span']\n",
    "                    if d['obj'] == 'target':\n",
    "                        begin, end = get_eid(span, ori_text)\n",
    "                        for token in conll:\n",
    "                            tid = token[0]\n",
    "                            if tid >= begin and tid <= end:\n",
    "                                token.append(lu)\n",
    "                                token.append(frame)\n",
    "                            else:\n",
    "                                token.append('_')\n",
    "                                token.append('_')\n",
    "                for d in deno['denotations']:\n",
    "                    fe = d['obj']\n",
    "                    span = d['span']\n",
    "                    if fe != 'target':\n",
    "                        begin, end = get_eid(span, ori_text)\n",
    "                        for token in conll:\n",
    "                            tid = token[0]\n",
    "                            if tid >= begin and tid <= end:\n",
    "                                token.append(fe)\n",
    "                for token in conll:\n",
    "                    if len(token) == 14:\n",
    "                        token.append('_')\n",
    "                conll = getBIO_list(conll)\n",
    "                result.append(conll)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except:\n",
    "                print('err2',anno_id)\n",
    "                pass\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            print('err1',sent_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Write Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_sejong():\n",
    "#     with open('./koreanframenet/resource/KFN_annotations_from_sejong.json','r') as f:\n",
    "#         sejong = json.load(f)\n",
    "#     return sejong\n",
    "# sejong = load_sejong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "err2 5619\n",
      "err2 15357\n",
      "err2 17912\n",
      "err2 19178\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def write_data():\n",
    "    with open('./data/data_sent_list.json', 'r') as f:\n",
    "        d = json.load(f)\n",
    "    dev = d['dev']\n",
    "    tst = d['tst']\n",
    "    trn = d['trn']\n",
    "\n",
    "#     for s in sejong:\n",
    "#         for a in s['annotations']:\n",
    "#             anno = {}\n",
    "#             anno['sent_id'] = a['ko_annotation_id']\n",
    "#             anno['ko_text'] = a['text']\n",
    "#             anno['annotations'] = [a]\n",
    "\n",
    "#             conlls = genCoNLLdata(anno)\n",
    "#             for conll in conlls:\n",
    "#                 add = False\n",
    "#                 for t in conll:\n",
    "#                     if t[12] != '_':\n",
    "#                         add = True\n",
    "#                 if add == True:\n",
    "#                     with open('./koreanframenet/data/exemplar.tsv', 'a') as f:\n",
    "#                         sent_id = str(anno['sent_id'])\n",
    "#                         sent = anno['ko_text']\n",
    "#                         f.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "#                         f.write(\"#text:\"+sent+\"\\n\")\n",
    "#                         for token in conll:\n",
    "#                             line = '\\t'.join(map(str,token))\n",
    "#                             f.write(line+\"\\n\")\n",
    "#                         f.write('\\n')\n",
    "        \n",
    "    for i in koanno:\n",
    "        s_id = i['text']['sent_id']\n",
    "        print(s_id)\n",
    "        if s_id in tst:\n",
    "            anno = {}\n",
    "            anno['sent_id'] = i['text']['sent_id']\n",
    "            anno['ko_text'] = i['text']['ko_text']\n",
    "            anno['annotations'] = i['frameAnnotation']['ko_annotations']\n",
    "            conlls = genCoNLLdata(anno)\n",
    "            for conll in conlls:\n",
    "                add = False\n",
    "                for t in conll:\n",
    "                    if t[12] != '_':\n",
    "                        add = True\n",
    "                if add == True:\n",
    "                    with open('./koreanframenet/data/test.tsv', 'a') as f:\n",
    "                        sent_id = str(anno['sent_id'])\n",
    "                        sent = anno['ko_text']\n",
    "                        f.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "                        f.write(\"#text:\"+sent+\"\\n\")\n",
    "                        for token in conll:\n",
    "                            line = '\\t'.join(map(str,token))\n",
    "                            f.write(line+\"\\n\")\n",
    "                        f.write('\\n')\n",
    "        elif s_id in dev:\n",
    "            anno = {}\n",
    "            anno['sent_id'] = i['text']['sent_id']\n",
    "            anno['ko_text'] = i['text']['ko_text']\n",
    "            anno['annotations'] = i['frameAnnotation']['ko_annotations']\n",
    "            conlls = genCoNLLdata(anno)\n",
    "            for conll in conlls:\n",
    "                add = False\n",
    "                for t in conll:\n",
    "                    if t[12] != '_':\n",
    "                        add = True\n",
    "                if add == True:\n",
    "                    with open('./koreanframenet/data/dev.tsv', 'a') as f:\n",
    "                        sent_id = str(anno['sent_id'])\n",
    "                        sent = anno['ko_text']\n",
    "                        f.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "                        f.write(\"#text:\"+sent+\"\\n\")\n",
    "                        for token in conll:\n",
    "                            line = '\\t'.join(map(str,token))\n",
    "                            f.write(line+\"\\n\")\n",
    "                        f.write('\\n')\n",
    "        else:\n",
    "            anno = {}\n",
    "            anno['sent_id'] = i['text']['sent_id']\n",
    "            anno['ko_text'] = i['text']['ko_text']\n",
    "            anno['annotations'] = i['frameAnnotation']['ko_annotations']\n",
    "\n",
    "            conlls = genCoNLLdata(anno)\n",
    "            for conll in conlls:\n",
    "                add = False\n",
    "                for t in conll:\n",
    "                    if t[12] != '_':\n",
    "                        add = True\n",
    "                if add == True:\n",
    "                    with open('./koreanframenet/data/training.tsv', 'a') as f:\n",
    "                        sent_id = str(anno['sent_id'])\n",
    "                        sent = anno['ko_text']\n",
    "                        f.write(\"#sentid:\"+sent_id+\"\\n\")\n",
    "                        f.write(\"#text:\"+sent+\"\\n\")\n",
    "                        for token in conll:\n",
    "                            line = '\\t'.join(map(str,token))\n",
    "                            f.write(line+\"\\n\")\n",
    "                        f.write('\\n')\n",
    "    print('done')\n",
    "#write_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
