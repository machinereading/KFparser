{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중국은 파키스탄, 이란, 그리고 북한을 포함한, 여러 나라의 미사일 프로그램에 기술과 전문가를 제공하였다.\n",
      "이란은 화학 시설과 과거 화학무기 비축에 관한 선언서를 제출하였는데, 이란은 화학무기 금지기구 조사관들이 있는 곳에서 화학무기 생산 장비를 파괴하였고, 화학 산업 시설들에 대해 화학무기 금지기구의 조사를 수 차례 받았다.\n",
      "이란은 화학 시설과 과거 화학무기 비축에 관한 선언서를 제출하였는데, 이란은 화학무기 금지기구 조사관들이 있는 곳에서 화학무기 생산 장비를 파괴하였고, 화학 산업 시설들에 대해 화학무기 금지기구의 조사를 수 차례 받았다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import etri\n",
    "\n",
    "f1 = './koreanframenet/data/bak/test.tsv'\n",
    "f2 = './koreanframenet/data/bak/training.tsv'\n",
    "f3 = './koreanframenet/data/bak/training_fe.tsv'\n",
    "files = [f1, f2, f3]\n",
    "\n",
    "def getCoNLL(lines, filename):\n",
    "    filetype = filename.split('/')[-1]\n",
    "    target_file = './'+filetype\n",
    "    result = []\n",
    "    sent = []\n",
    "    sent_ids = []\n",
    "    each_sent = {}\n",
    "    for line in lines:\n",
    "        line = line.rstrip('\\n')\n",
    "        if line.startswith('#'):\n",
    "            if line[1] == 's':\n",
    "                #sent_id = line.split(':')[1]\n",
    "                each_sent['sent_id'] = line\n",
    "            else:\n",
    "                #text = line[6:]\n",
    "                each_sent['text'] = line\n",
    "        else:\n",
    "            if line != '':\n",
    "                token = line.split('\\t')\n",
    "                sent.append(token)\n",
    "            else:\n",
    "                each_sent['conll'] = sent\n",
    "                result.append(each_sent)\n",
    "                each_sent = {}\n",
    "                sent = []\n",
    "    with open(target_file, 'a') as f:\n",
    "        for i in result:\n",
    "            sent_id = i['sent_id']\n",
    "            text = i['text']\n",
    "            ori_text = text[6:]\n",
    "            f.write(sent_id+'\\n')\n",
    "            f.write(text+'\\n')\n",
    "            conll = i['conll']\n",
    "            etri_result = etri.getETRI_CoNLL2006(ori_text)\n",
    "            morp = []\n",
    "            for i in range(len(conll)):\n",
    "                conll[i][2] = etri_result[i][2]\n",
    "                if conll[i][11] != '_':\n",
    "                    conll[i][11] = conll[i][11].lower()\n",
    "            for token in conll:\n",
    "                line = '\\t'.join(map(str,token))\n",
    "                f.write(line+'\\n')\n",
    "            f.write('\\n')\n",
    "    print('write:', target_file)\n",
    "\n",
    "def genData():\n",
    "    for i in files:\n",
    "        with open(i, 'r') as f:\n",
    "            d = f.readlines()\n",
    "            conll = getCoNLL(d, i)\n",
    "            \n",
    "#genData()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### load KFN ###\n"
     ]
    }
   ],
   "source": [
    "from koreanframenet import kfn\n",
    "def load_kfn():\n",
    "    with open('./koreanframenet/resource/KFN_lus.json', 'r') as f:\n",
    "        kolu = json.load(f)\n",
    "    with open('./koreanframenet/resource/KFN_annotations.json','r') as f:\n",
    "        koanno = json.load(f)\n",
    "    print('### load KFN ###')\n",
    "    return kolu, koanno\n",
    "kolu, koanno = load_kfn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add surfaceform for KNF_lus.json\n",
    "\n",
    "# get eojeol id (i.e. token id) from 'span' and 'text'\n",
    "def get_eid(span, ori_text):\n",
    "    text = ' '.join(ori_text.split())\n",
    "    sent_list = text.split(' ')\n",
    "    #print(sent_list)\n",
    "    b,e = int(span['begin']), int(span['end'])\n",
    "    n = 0\n",
    "    k = 0\n",
    "    ori_text_list = ori_text.split(' ')\n",
    "    #print(ori_text_list)\n",
    "    for i in ori_text_list:\n",
    "        if i == '':\n",
    "            k = k+1\n",
    "    #print('k:',k)\n",
    "    e_num = 0\n",
    "    e_list = []\n",
    "    for eojeol in sent_list:\n",
    "        if eojeol == '':\n",
    "            pass\n",
    "        else:\n",
    "            eojeol_begin_offset = n\n",
    "            eojeol_end_offset = n+len(eojeol)\n",
    "            n = eojeol_end_offset+1\n",
    "            t = (eojeol_begin_offset, eojeol_end_offset, e_num, eojeol)\n",
    "            e_list.append(t)\n",
    "            e_num = e_num +1\n",
    "    begin, end = 0,0\n",
    "    for i in e_list:\n",
    "        if b <= i[0]+k or (b >=i[0] and e <= i[1]+k):\n",
    "            begin = i[2]\n",
    "            break\n",
    "    for i in e_list:\n",
    "        if e <= i[1]+k:\n",
    "            end = i[2]\n",
    "            break\n",
    "    #print(e_list)\n",
    "    #print(b,e)\n",
    "    #print(span)\n",
    "    #print(begin,end)\n",
    "    return begin, end\n",
    "def get_eojeol(span, ori_text):\n",
    "    text = ' '.join(ori_text.split())\n",
    "    #text = ori_text\n",
    "    begin, end = get_eid(span, ori_text)\n",
    "    end = end+1\n",
    "    text_list = text.split(' ')\n",
    "    eojeol_list = text_list[begin:end]\n",
    "    eojeol_list = [ e.replace('.', '') for e in eojeol_list ]\n",
    "    eojeol_list = [ e.replace(',', '') for e in eojeol_list ]\n",
    "    eojeol_list = [ e.replace('!', '') for e in eojeol_list ]\n",
    "    eojeol_list = [ e.replace('?', '') for e in eojeol_list ]\n",
    "    eojeol = ' '.join(eojeol_list)\n",
    "    #print(eojeol)\n",
    "    return eojeol\n",
    "def add_surfaceforms():\n",
    "    new_kolu = []\n",
    "    err = 0\n",
    "    for i in kolu:\n",
    "        surface_forms = []\n",
    "        luid = i['lu_id']\n",
    "\n",
    "        #if luid == 129:\n",
    "        #if luid == 193:\n",
    "        \n",
    "        #if luid == 5:\n",
    "        #if luid == 249:\n",
    "        #if luid == 5392:\n",
    "\n",
    "        annos = kfn.annotation(luid)\n",
    "        print('###', luid, i['lu'])\n",
    "        for anno in annos:\n",
    "            denos = anno['denotations']\n",
    "            text = anno['text']\n",
    "            #print(text)\n",
    "            for deno in denos:\n",
    "\n",
    "                if deno['obj'] == 'target' or deno['obj'] == 'Target':\n",
    "                    #print(deno)\n",
    "                    target_span = deno['span']\n",
    "                    b,e = target_span['begin'], target_span['end']\n",
    "                    #annotation error 제외\n",
    "                    if type(b) != str:\n",
    "                        target = get_eojeol(target_span, text)\n",
    "                        target_anno = text[b:e]\n",
    "                        if target_anno in target:\n",
    "                            #print('target_anno:',target_anno, 'target:', target)\n",
    "                            surface_forms.append(target)\n",
    "                        else:\n",
    "                            err = err+1\n",
    "                            #print('target_anno:',target_anno, 'target:', target)\n",
    "                    else:\n",
    "                        #e = e+1\n",
    "                        pass\n",
    "        surface_forms = list(set(surface_forms))\n",
    "        i['surface_forms'] = surface_forms\n",
    "        #print('')\n",
    "        new_kolu.append(i)\n",
    "        print('error:', err)\n",
    "        #else:\n",
    "            #pass\n",
    "        #break\n",
    "    #print(new_kolu)\n",
    "\n",
    "    #with open('./resource/KFN_lus.json','w') as f:\n",
    "        #json.dump(new_kolu, f, ensure_ascii=False, indent=4)\n",
    "#add_surfaceforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fid': 43, 'lu': '선언서.n.Statement', 'lu_id': 1, 'lexeme': '선언서', 'fe_list': ['speaker', 'topic'], 'surface_forms': ['선언서를'], 'mapSejong': False, 'pos': 'NNG', 'frameName': 'Statement', 'lemma_var': ['선언서'], 'publish': True, 'ko_annotation_id': [1], 'sejong_annotation_id': [], 'en_lu': ['declaration']}\n",
      "{'fid': 43, 'lu': '선언서.n.Statement', 'lu_id': 1, 'lexeme': '선언서', 'fe_list': ['speaker', 'topic'], 'surface_forms': ['선언서를'], 'mapSejong': False, 'pos': 'NNG', 'frameName': 'Statement', 'lemma_var': ['선언서'], 'publish': True, 'ko_annotation_id': [1], 'sejong_annotation_id': [], 'en_lu': ['declaration']}\n"
     ]
    }
   ],
   "source": [
    "def gen_fe_list_for_lu():\n",
    "    n = 0\n",
    "    for i in kolu:\n",
    "        luid = i['lu_id']\n",
    "        anno = kfn.annotation(luid)\n",
    "        felist = []\n",
    "        for j in anno:\n",
    "            for d in j['denotations']:\n",
    "                if d['obj'] != 'target':\n",
    "                    felist.append(d['obj'])\n",
    "        felist = list(set(felist))\n",
    "        i['fe_list'] = felist\n",
    "        print(i)\n",
    "        break\n",
    "    print(kolu[0])\n",
    "        #print(n, '/', len(kolu))\n",
    "    #with open('./koreanframenet/resource/KFN_lus.json','w') as f:\n",
    "        #json.dump(kolu, f, ensure_ascii=False, indent=4)\n",
    "gen_fe_list_for_lu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
