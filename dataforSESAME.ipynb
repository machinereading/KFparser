{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_file = './koreanframenet/data/training.tsv'\n",
    "test_file = './koreanframenet/data/test.tsv'\n",
    "file_list = [train_file, test_file]\n",
    "target_dir = './data/opensesame/'\n",
    "\n",
    "def get_data(lines, file_name):\n",
    "    file_type = file_name.split('/')[-1]\n",
    "    print(file_type)\n",
    "    result = []\n",
    "    sent = []\n",
    "    exemplar_sent_num = 0\n",
    "    train_sent_num = 0\n",
    "    test_sent_num = 0\n",
    "    for line in lines:\n",
    "        d = {}\n",
    "        #line = line.rstip('\\n')\n",
    "        if line.startswith('#'):\n",
    "            if line[1] == 's':\n",
    "                if 'sejong' in line:\n",
    "                    sent_type = 'exemplar'\n",
    "                else:\n",
    "                    if 'training' in file_type:\n",
    "                        sent_type = 'train'\n",
    "                    else:\n",
    "                        sent_type = 'test'\n",
    "            else:\n",
    "                sents = line[6:]\n",
    "        else:\n",
    "            if sent_type == 'exemplar':\n",
    "                if line != '\\n':           \n",
    "                    line_list = line.split('\\t')\n",
    "                    line_list[6] = str(exemplar_sent_num)\n",
    "                    line_text = '\\t'.join(line_list)\n",
    "                    sent.append(line_text)\n",
    "                else:\n",
    "                    d['sent_type'] = sent_type\n",
    "                    d['sents'] = sents\n",
    "                    d['conll'] = sent\n",
    "                    result.append(d)\n",
    "                    sent = []\n",
    "                    exemplar_sent_num += 1\n",
    "            elif sent_type == 'train':\n",
    "                if line != '\\n':           \n",
    "                    line_list = line.split('\\t')\n",
    "                    line_list[6] = str(train_sent_num)\n",
    "                    line_text = '\\t'.join(line_list)\n",
    "                    sent.append(line_text)\n",
    "                else:\n",
    "                    d['sent_type'] = sent_type\n",
    "                    d['sents'] = sents\n",
    "                    d['conll'] = sent\n",
    "                    result.append(d)\n",
    "                    sent = []\n",
    "                    train_sent_num += 1\n",
    "            elif sent_type == 'test':\n",
    "                if line != '\\n':           \n",
    "                    line_list = line.split('\\t')\n",
    "                    line_list[6] = str(test_sent_num)\n",
    "                    line_text = '\\t'.join(line_list)\n",
    "                    sent.append(line_text)\n",
    "                else:\n",
    "                    d['sent_type'] = sent_type\n",
    "                    d['sents'] = sents\n",
    "                    d['conll'] = sent\n",
    "                    result.append(d)\n",
    "                    sent = []\n",
    "                    test_sent_num += 1\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "    print(len(result))\n",
    "    return result\n",
    "                \n",
    "        \n",
    "    \n",
    "\n",
    "def gen_data(file_name):\n",
    "    print('working for', file_name)\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    data = get_data(lines, file_name)    \n",
    "    \n",
    "    if 'training' in file_name:\n",
    "        train_file = target_dir+'fn1.7.fulltext.train.syntaxnet.conll'\n",
    "        train_sents_file = target_dir+'fn1.7.fulltext.train.syntaxnet.conll.sents'\n",
    "        train = open(train_file, 'w')\n",
    "        train_sents = open(train_sents_file, 'w')\n",
    "        examplar_file = target_dir+'fn1.7.exemplar.train.syntaxnet.conll'\n",
    "        examplar_sents_file = target_dir+'fn1.7.exemplar.train.syntaxnet.conll.sents'\n",
    "        examplar = open(examplar_file, 'w')\n",
    "        examplar_sents = open(examplar_sents_file, 'w')\n",
    "    else:\n",
    "        dev_file = target_dir+'fn1.7.dev.syntaxnet.conll'\n",
    "        dev_sents_file = target_dir+'fn1.7.dev.syntaxnet.conll.sents'\n",
    "        dev = open(dev_file, 'w')\n",
    "        dev_sents = open(dev_sents_file, 'w')   \n",
    "        test_file = target_dir+'fn1.7.test.syntaxnet.conll'\n",
    "        test_sents_file = target_dir+'fn1.7.test.syntaxnet.conll.sents'\n",
    "        test = open(test_file, 'w')\n",
    "        test_sents = open(test_sents_file, 'w')\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in data:\n",
    "        if i['sent_type'] == 'train':\n",
    "            train_sents.write(i['sents'])\n",
    "            for line in i['conll']:\n",
    "                train.write(line)\n",
    "            train.write('\\n')\n",
    "        elif i['sent_type'] == 'exemplar':\n",
    "            examplar_sents.write(i['sents'])\n",
    "            for line in i['conll']:\n",
    "                examplar.write(line)\n",
    "            examplar.write('\\n')\n",
    "        elif i['sent_type'] == 'test':\n",
    "            test_sents.write(i['sents'])\n",
    "            dev_sents.write(i['sents'])\n",
    "            for line in i['conll']:\n",
    "                test.write(line)\n",
    "                dev.write(line)\n",
    "            test.write('\\n')\n",
    "            dev.write('\\n')\n",
    "    #dev.close()\n",
    "    #dev_sents.close()\n",
    "    #train.close()\n",
    "    #train_sents.close()\n",
    "    #test.close()\n",
    "    #test_sents.close()\n",
    "    #examplar.close()\n",
    "    #examplar_sents.close()\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in file_list:\n",
    "    gen_data(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
