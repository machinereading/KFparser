{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5f1004fc90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "import preprocessor\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GeForce GTX 1080 , # of gpu:(1)\n",
      "Torch Version: 9.0.176\n"
     ]
    }
   ],
   "source": [
    "print('GPU:', torch.cuda.get_device_name(0), ', # of gpu:('+str(torch.cuda.device_count())+')')\n",
    "print('Torch Version:', torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### loading data now...\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data, dev_data, exemplar_data = preprocessor.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training_data\n",
      " - number of sentences: 3220\n",
      " - number of annotations: 12431 \n",
      "\n",
      "# test_data\n",
      " - number of sentences: 1124\n",
      " - number of annotations: 4382 \n",
      "\n",
      "# dev_data\n",
      " - number of sentences: 183\n",
      " - number of annotations: 624 \n",
      "\n",
      "# exemplar data (from sejong)\n",
      " - number of sentences: 10967\n",
      " - number of annotations: 10967 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor.data_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CONFIGURATION ###\n",
      "\n",
      "{'batch_size': 64,\n",
      " 'hidden_dim': 64,\n",
      " 'learning_rate': 0.0005,\n",
      " 'lstm_depth': 2,\n",
      " 'lstm_dim': 64,\n",
      " 'lstm_input_dim': 64,\n",
      " 'lu_dim': 64,\n",
      " 'lu_pos_dim': 5,\n",
      " 'num_epochs': 25,\n",
      " 'pos_dim': 4,\n",
      " 'token_dim': 60,\n",
      " 'using_GPU': True}\n"
     ]
    }
   ],
   "source": [
    "configuration = {'token_dim': 60,\n",
    "                 'hidden_dim': 64,\n",
    "                 'pos_dim': 4,\n",
    "                 'lu_dim': 64,\n",
    "                 'lu_pos_dim': 5,\n",
    "                 'lstm_input_dim': 64,\n",
    "                 'lstm_dim': 64,\n",
    "                 'lstm_depth': 2,\n",
    "                 'hidden_dim': 64,\n",
    "                 'num_epochs': 25,\n",
    "                 'learning_rate': 0.0005,\n",
    "                 'using_GPU': True,\n",
    "                 'batch_size': 64}\n",
    "print('\\n### CONFIGURATION ###\\n')\n",
    "pprint.pprint(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model/lstm180731'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper-parameters\n",
    "usingGPU = configuration['using_GPU']\n",
    "TOKDIM= configuration['token_dim']\n",
    "POSDIM = configuration['pos_dim']\n",
    "LUDIM = configuration['lu_dim']\n",
    "LPDIM = configuration['lu_pos_dim']\n",
    "INPDIM = LUDIM + LPDIM\n",
    "LSTMINPDIM = configuration['lstm_input_dim']\n",
    "LSTMDIM = configuration['lstm_dim']\n",
    "LSTMDEPTH = configuration['lstm_depth']\n",
    "HIDDENDIM = configuration['hidden_dim']\n",
    "NUM_EPOCHS = configuration['num_epochs']\n",
    "learning_rate = configuration['learning_rate']\n",
    "batch_size = configuration['batch_size']\n",
    "\n",
    "# num_layers = 1\n",
    "# num_epochs = 5\n",
    "# num_samples = 1000     # number of words to be sampled\n",
    "# batch_size = 20\n",
    "# seq_length = 30\n",
    "seq_length = 0\n",
    "for i in training_data:\n",
    "    new_len = len(i)\n",
    "    if new_len > seq_length:\n",
    "        seq_length = new_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###  word vocab size: 21171\n",
      "### frame vocab size: 657\n"
     ]
    }
   ],
   "source": [
    "def prepare_index():\n",
    "    word_to_ix = {}\n",
    "    pos_to_ix = {}\n",
    "    frame_to_ix = {}\n",
    "    for tokens in training_data:\n",
    "        for t in tokens:\n",
    "            word = t[1]\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)            \n",
    "#             pos = t[4]\n",
    "#             if pos not in pos_to_ix:\n",
    "#                 pos_to_ix[pos] = len(pos_to_ix)\n",
    "            frame = t[13]\n",
    "            if frame != '_':\n",
    "                if frame not in frame_to_ix:\n",
    "                    frame_to_ix[frame] = len(frame_to_ix)\n",
    "    return word_to_ix, frame_to_ix\n",
    "word_to_ix, frame_to_ix = prepare_index()\n",
    "print('###  word vocab size:', len(word_to_ix))\n",
    "print('### frame vocab size:', len(frame_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence(tokens):\n",
    "    sentence, pos, frame = [],[],[]\n",
    "    for token in tokens:\n",
    "        w,p,f = token[1],token[4],token[13]\n",
    "        sentence.append(w)\n",
    "        pos.append(p)\n",
    "        frame.append(f)\n",
    "    return sentence, pos, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    if usingGPU:\n",
    "        return torch.tensor(idxs).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frame_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq if w != '_']\n",
    "    idxs = list(set(idxs))\n",
    "    if usingGPU:\n",
    "        return torch.tensor(idxs).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def gen_sequence_data(data, bs=batch_size):\n",
    "# #     print('\\n### generate batch data ###')\n",
    "# #     print('batch size:', bs)\n",
    "# #     num_batches = len(data) // bs\n",
    "# #     print('num batches:', num_batches)\n",
    "\n",
    "\n",
    "# def gen_sequence_data(data, bs=batch_size):\n",
    "#     print('\\n### generate batch data ###')\n",
    "#     print('batch size:', bs)\n",
    "#     num_batches = len(data) // bs\n",
    "#     print('num batches:', num_batches)\n",
    "#     seq_data = []\n",
    "#     for tokens in data:\n",
    "#         sentence, pos, frame = prepare_sentence(tokens)\n",
    "#         sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "#         frames = prepare_frame_sequence(frame, frame_to_ix)\n",
    "#         targetpositions = get_targetpositions(tokens)\n",
    "#         seq_data.append( (sentence_in, frames, targetpositions) )\n",
    "# #     return seq_data\n",
    "#     seq_data = seq_data[:num_batches*bs]\n",
    "    \n",
    "#     n = 0\n",
    "#     batch_data = []\n",
    "#     sent_list, frame_list, targetpositions = [],[],[]\n",
    "#     for (sent,frame,targetposition) in rev_data:\n",
    "#         sent_list.append(sent)\n",
    "#         frame_list.append(frame)\n",
    "#         targetpositions.append(targetposition)\n",
    "#         n += 1\n",
    "#         if n % bs == 0:\n",
    "#             intuple = ( sent_list, frame_list, targetposition )\n",
    "#             batch_data.append(intuple)\n",
    "#             sent_list, frame_list = [],[]\n",
    "#     print(len(batch_data))\n",
    "#     return batch_data\n",
    "\n",
    "\n",
    "# d = gen_sequence_data(training_data)\n",
    "\n",
    "\n",
    "\n",
    "# ## TODO 0803: batch data 다시만들기\n",
    "# #batch 0 : 1개 튜플, 각 튜플에는 sentence tensor 64개, frame tensor 64개\n",
    "# # 그리고 padding 까지 해서 --> 주말 돌림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_data = gen_sequence_data(training_data)\n",
    "# n = 0\n",
    "# for i in seq_data:\n",
    "#     n += 1\n",
    "#     if n >= 5:\n",
    "#         print(i)\n",
    "#         print('\\n ###')\n",
    "        \n",
    "#     if n > 11:\n",
    "#         break\n",
    "\n",
    "# print(seq_data[0])\n",
    "\n",
    "\n",
    "# batch_data = torch.utils.data.DataLoader(seq_data, batch_size=2)\n",
    "\n",
    "# print('batch')\n",
    "# n = 0\n",
    "# for i in batch_data:\n",
    "#     print(i)\n",
    "#     n += 1\n",
    "#     if n >= 11:\n",
    "#         print(i)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frame_vector(seq, to_ix):\n",
    "    if usingGPU:\n",
    "        frame_vector =  torch.zeros(len(to_ix)).type(torch.cuda.LongTensor)\n",
    "#         frame_vector[0][fid] = 1\n",
    "    else:\n",
    "        frame_vector =  torch.zeros(len(to_ix), dtype=torch.long)\n",
    "#         frame_vector[0][fid] = 1\n",
    "    for f in seq:\n",
    "        if f != '_':\n",
    "            fid = frame_to_ix[f]\n",
    "            frame_vector[fid] = 1\n",
    "    return frame_vector\n",
    "\n",
    "# _, _, seq = prepare_sentence(training_data[50])\n",
    "# d = prepare_frame_vector(seq, frame_to_ix)\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targetpositions(tokens):\n",
    "    positions = []\n",
    "    for i in tokens:\n",
    "        if i[12] != '_':\n",
    "            positions.append(int(i[0]))\n",
    "    positions = np.asarray(positions)\n",
    "    positions = torch.from_numpy(positions)\n",
    "    if usingGPU:\n",
    "        return positions.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_span(sentence, targetpositions):\n",
    "    start, end = int(targetpositions[0]), int(targetpositions[-1])\n",
    "    span = {}\n",
    "    if start == 0: span['start'] = 0\n",
    "    else: span['start'] = start -1\n",
    "    if end == len(sentence): span['end'] = end+1\n",
    "    else: span['end'] = end+2\n",
    "    return span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, TOKDIM)\n",
    "        \n",
    "        # 1st LSTM network (bi-LSTM)\n",
    "        self.lstm_1 = nn.LSTM(TOKDIM, HIDDENDIM//2, bidirectional=True)\n",
    "        self.hidden_lstm_1 = self.init_hidden_lstm_1()\n",
    "        \n",
    "        # 2nd LSTM network (LSTM)\n",
    "        self.hidden_lstm_2 = self.init_hidden_lstm_2()\n",
    "        self.lstm_2 = nn.LSTM(HIDDENDIM, HIDDENDIM)\n",
    "        \n",
    "        self.target2hidden = nn.Linear(HIDDENDIM, HIDDENDIM)\n",
    "        self.hidden2tag = nn.Linear(HIDDENDIM, tagset_size) \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if usingGPU:\n",
    "            return (torch.zeros(1, 1, HIDDENDIM).cuda(),\n",
    "                torch.zeros(1, 1, HIDDENDIM).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(1, 1, HIDDENDIM),\n",
    "                torch.zeros(1, 1, HIDDENDIM))\n",
    "    \n",
    "    def init_hidden_lstm_1(self):\n",
    "        if usingGPU:\n",
    "            return (torch.zeros(2, 1, HIDDENDIM//2).cuda(),\n",
    "                torch.zeros(2, 1, HIDDENDIM//2).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(2, 1, HIDDENDIM//2),\n",
    "                torch.zeros(2, 1, HIDDENDIM//2))\n",
    "        \n",
    "    def init_hidden_lstm_2(self):\n",
    "        if usingGPU:\n",
    "            return (torch.zeros(1, 1, HIDDENDIM).cuda(),\n",
    "                torch.zeros(1, 1, HIDDENDIM).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(1, 1, HIDDENDIM),\n",
    "                torch.zeros(1, 1, HIDDENDIM))\n",
    "\n",
    "    def forward(self, sentence, targetpositions):\n",
    "#         if usingGPU: \n",
    "#             sentence.cuda()\n",
    "#         else: \n",
    "#             pass\n",
    "\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = embeds.view(len(sentence), 1, -1)\n",
    "        lstm_out_1, self.hidden_lstm_1 = self.lstm_1(\n",
    "            embeds, self.hidden_lstm_1)\n",
    "\n",
    "        span = get_target_span(sentence, targetpositions)  \n",
    "\n",
    "        target_lstm = lstm_out_1[span['start']:span['end']]\n",
    "        \n",
    "\n",
    "        \n",
    "        lstm_out_2, self.hidden = self.lstm_2(\n",
    "            target_lstm, self.hidden_lstm_2)        \n",
    "\n",
    "        target_vec = lstm_out_2[-1]\n",
    "\n",
    "        tag_space = self.target2hidden(target_vec)        \n",
    "        tag_space = F.relu(tag_space)\n",
    "        tag_space = self.hidden2tag(tag_space)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0134,  0.0409, -0.0635, -0.0946,  0.0312,  0.0076,  0.2187,\n",
      "          -0.0281,  0.2215, -0.0084, -0.2766, -0.0394, -0.1148,  0.2790,\n",
      "          -0.3599, -0.2090,  0.2519,  0.1238, -0.4554, -0.1012, -0.1137,\n",
      "           0.4293,  0.1434,  0.2845,  0.4047, -0.0250,  0.1127, -0.2835,\n",
      "           0.0169,  0.3802,  0.0872, -0.2760, -0.0473, -0.0898,  0.2575,\n",
      "           0.0594,  0.2365,  0.2269,  0.2389,  0.0308, -0.3228, -0.1142,\n",
      "          -0.0425,  0.2054, -0.0885, -0.2188, -0.1013,  0.0286, -0.2144,\n",
      "          -0.0650,  0.1336, -0.0683, -0.0433, -0.0799, -0.1039, -0.0689,\n",
      "           0.4191,  0.1646,  0.1187, -0.2459, -0.2595,  0.1478, -0.2272,\n",
      "           0.0298]],\n",
      "\n",
      "        [[-0.0516, -0.0891, -0.0787, -0.2005, -0.1561,  0.0661,  0.0652,\n",
      "          -0.0592,  0.0382,  0.1762, -0.0740,  0.0209, -0.0110,  0.1447,\n",
      "          -0.0998, -0.2518,  0.3422,  0.1773, -0.1757,  0.0406, -0.0058,\n",
      "          -0.0039, -0.0054, -0.0549,  0.0693,  0.1132,  0.0704, -0.0102,\n",
      "           0.0260,  0.3198,  0.2714, -0.0640,  0.0412,  0.1617,  0.2564,\n",
      "          -0.1106,  0.2880, -0.1383,  0.1372,  0.0190, -0.0121, -0.4475,\n",
      "           0.0577,  0.0820, -0.0783, -0.0391,  0.1576,  0.3935, -0.1216,\n",
      "           0.0052,  0.5715,  0.1863, -0.0177, -0.0369, -0.1206, -0.3909,\n",
      "           0.0019,  0.0453,  0.0510, -0.2133,  0.1667, -0.0434, -0.2501,\n",
      "           0.1639]],\n",
      "\n",
      "        [[ 0.1307, -0.0320, -0.0892, -0.0691, -0.0348,  0.1086, -0.0488,\n",
      "          -0.1041,  0.0320, -0.1963, -0.0644, -0.0079, -0.1576,  0.2179,\n",
      "          -0.1028, -0.1827,  0.1517,  0.1202, -0.2133,  0.0610,  0.0314,\n",
      "          -0.1046,  0.0071,  0.1270,  0.0008,  0.1732, -0.0317, -0.1281,\n",
      "          -0.0013, -0.0025,  0.0256,  0.0772, -0.0101,  0.2218,  0.0932,\n",
      "          -0.0827,  0.1838,  0.1597, -0.0283,  0.1620, -0.0117, -0.1102,\n",
      "           0.0985,  0.4612, -0.1015,  0.1760,  0.5005,  0.1756,  0.0589,\n",
      "           0.0192,  0.3071,  0.2273, -0.1573,  0.2114, -0.2533, -0.0652,\n",
      "          -0.2800, -0.0549, -0.0894, -0.2355, -0.0535, -0.0630, -0.1708,\n",
      "           0.2272]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0091,  0.0690, -0.0866, -0.0882,  0.0279,  0.0036,  0.2059,\n",
      "          -0.0281,  0.2004,  0.0112, -0.2406, -0.0501, -0.0909,  0.2878,\n",
      "          -0.3364, -0.2109,  0.2598,  0.1287, -0.4621, -0.1118, -0.1015,\n",
      "           0.4063,  0.1256,  0.2982,  0.4232, -0.0280,  0.1055, -0.2757,\n",
      "           0.0149,  0.3659,  0.0894, -0.2644, -0.0512, -0.0975,  0.2658,\n",
      "           0.0738,  0.2387,  0.2415,  0.2470,  0.0334, -0.3105, -0.1017,\n",
      "          -0.0227,  0.2024, -0.0936, -0.2226, -0.0913,  0.0131, -0.2043,\n",
      "          -0.0736,  0.1271, -0.0609, -0.0530, -0.0883, -0.1068, -0.0766,\n",
      "           0.4260,  0.1572,  0.1145, -0.2596, -0.2519,  0.1723, -0.2034,\n",
      "           0.0258]],\n",
      "\n",
      "        [[-0.0546, -0.0566, -0.0865, -0.1902, -0.1782,  0.0442,  0.0536,\n",
      "          -0.0665,  0.0167,  0.1994, -0.0534,  0.0100,  0.0086,  0.1541,\n",
      "          -0.0941, -0.2475,  0.3528,  0.1803, -0.1898,  0.0242,  0.0141,\n",
      "          -0.0282, -0.0135, -0.0377,  0.0942,  0.0945,  0.0585, -0.0198,\n",
      "           0.0233,  0.2989,  0.2868, -0.0554,  0.0381,  0.1393,  0.2747,\n",
      "          -0.0941,  0.2869, -0.1252,  0.1550,  0.0279, -0.0068, -0.4368,\n",
      "           0.0649,  0.0771, -0.0878, -0.0443,  0.1695,  0.3853, -0.1099,\n",
      "          -0.0067,  0.5561,  0.1947, -0.0406, -0.0391, -0.1274, -0.4046,\n",
      "           0.0159,  0.0301,  0.0453, -0.2345,  0.1794, -0.0255, -0.2283,\n",
      "           0.1488]],\n",
      "\n",
      "        [[ 0.1169, -0.0235, -0.0996, -0.0585, -0.0534,  0.0902, -0.0511,\n",
      "          -0.1125,  0.0177, -0.1762, -0.0435, -0.0173, -0.1389,  0.2401,\n",
      "          -0.0908, -0.1758,  0.1701,  0.1292, -0.2299,  0.0463,  0.0462,\n",
      "          -0.1322, -0.0024,  0.1478,  0.0268,  0.1413, -0.0557, -0.1449,\n",
      "          -0.0098, -0.0069,  0.0387,  0.0879, -0.0102,  0.1923,  0.1050,\n",
      "          -0.0521,  0.1676,  0.1825, -0.0171,  0.1793, -0.0076, -0.0983,\n",
      "           0.1050,  0.4409, -0.1205,  0.1556,  0.5264,  0.1780,  0.0699,\n",
      "          -0.0002,  0.2830,  0.2426, -0.1891,  0.2169, -0.2699, -0.0788,\n",
      "          -0.2584, -0.0761, -0.1220, -0.2582, -0.0400, -0.0511, -0.1604,\n",
      "           0.2117]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0093,  0.0976, -0.1084, -0.0852,  0.0245, -0.0002,  0.2053,\n",
      "          -0.0291,  0.1856,  0.0307, -0.2026, -0.0634, -0.0720,  0.2972,\n",
      "          -0.3130, -0.2142,  0.2681,  0.1339, -0.4700, -0.1232, -0.0904,\n",
      "           0.3840,  0.1119,  0.3117,  0.4414, -0.0310,  0.0990, -0.2701,\n",
      "           0.0132,  0.3510,  0.0897, -0.2534, -0.0553, -0.1044,  0.2745,\n",
      "           0.0876,  0.2484,  0.2570,  0.2555,  0.0360, -0.2984, -0.0897,\n",
      "          -0.0038,  0.1995, -0.0981, -0.2266, -0.0809,  0.0005, -0.1952,\n",
      "          -0.0823,  0.1211, -0.0526, -0.0631, -0.0900, -0.1100, -0.0842,\n",
      "           0.4327,  0.1515,  0.1099, -0.2737, -0.2485,  0.1972, -0.1798,\n",
      "           0.0220]],\n",
      "\n",
      "        [[-0.0551, -0.0248, -0.0940, -0.1847, -0.2005,  0.0244,  0.0501,\n",
      "          -0.0736,  0.0040,  0.2231, -0.0330, -0.0019,  0.0237,  0.1636,\n",
      "          -0.0896, -0.2583,  0.3638,  0.1864, -0.2046,  0.0076,  0.0349,\n",
      "          -0.0499, -0.0164, -0.0204,  0.1185,  0.0765,  0.0474, -0.0291,\n",
      "           0.0214,  0.2779,  0.2989, -0.0467,  0.0350,  0.1175,  0.2932,\n",
      "          -0.0781,  0.2960, -0.1119,  0.1732,  0.0373, -0.0009, -0.4261,\n",
      "           0.0723,  0.0723, -0.0971, -0.0498,  0.1818,  0.3801, -0.0992,\n",
      "          -0.0187,  0.5410,  0.2033, -0.0639, -0.0375, -0.1345, -0.4181,\n",
      "           0.0298,  0.0148,  0.0396, -0.2561,  0.1882, -0.0078, -0.2065,\n",
      "           0.1341]],\n",
      "\n",
      "        [[ 0.1055, -0.0158, -0.1105, -0.0495, -0.0737,  0.0738, -0.0490,\n",
      "          -0.1216,  0.0181, -0.1569, -0.0230, -0.0275, -0.1274,  0.2620,\n",
      "          -0.0799, -0.1750,  0.1889,  0.1387, -0.2472,  0.0319,  0.0639,\n",
      "          -0.1597, -0.0023,  0.1685,  0.0509,  0.1107, -0.0795, -0.1611,\n",
      "          -0.0158, -0.0114,  0.0520,  0.0997, -0.0105,  0.1625,  0.1170,\n",
      "          -0.0223,  0.1615,  0.2061, -0.0062,  0.1969, -0.0038, -0.0877,\n",
      "           0.1166,  0.4199, -0.1400,  0.1356,  0.5515,  0.1803,  0.0806,\n",
      "          -0.0187,  0.2595,  0.2577, -0.2212,  0.2279, -0.2869, -0.0932,\n",
      "          -0.2374, -0.0988, -0.1547, -0.2808, -0.0276, -0.0396, -0.1505,\n",
      "           0.1971]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0164,  0.1176, -0.1280, -0.0858,  0.0209, -0.0032,  0.2038,\n",
      "          -0.0301,  0.1866,  0.0506, -0.1640, -0.0772, -0.0703,  0.3076,\n",
      "          -0.2934, -0.2190,  0.2774,  0.1391, -0.4764, -0.1351, -0.0810,\n",
      "           0.3647,  0.1078,  0.3249,  0.4585, -0.0334,  0.0932, -0.2658,\n",
      "           0.0115,  0.3351,  0.0870, -0.2424, -0.0597, -0.1108,  0.2834,\n",
      "           0.1015,  0.2598,  0.2736,  0.2650,  0.0387, -0.2926, -0.0768,\n",
      "           0.0135,  0.1967, -0.1026, -0.2295, -0.0699, -0.0052, -0.1863,\n",
      "          -0.0911,  0.1164, -0.0442, -0.0737, -0.0882, -0.1133, -0.0919,\n",
      "           0.4385,  0.1467,  0.1051, -0.2882, -0.2493,  0.2234, -0.1566,\n",
      "           0.0186]],\n",
      "\n",
      "        [[-0.0518, -0.0058, -0.1010, -0.1836, -0.2226,  0.0089,  0.0461,\n",
      "          -0.0811,  0.0094,  0.2471, -0.0136, -0.0136,  0.0258,  0.1731,\n",
      "          -0.0867, -0.2746,  0.3751,  0.1941, -0.2187, -0.0094,  0.0568,\n",
      "          -0.0687, -0.0135, -0.0032,  0.1407,  0.0602,  0.0370, -0.0376,\n",
      "           0.0190,  0.2556,  0.3002, -0.0376,  0.0319,  0.0966,  0.3120,\n",
      "          -0.0624,  0.3096, -0.0987,  0.1922,  0.0471,  0.0035, -0.4150,\n",
      "           0.0793,  0.0673, -0.1067, -0.0549,  0.1941,  0.3818, -0.0893,\n",
      "          -0.0303,  0.5273,  0.2120, -0.0883, -0.0345, -0.1421, -0.4321,\n",
      "           0.0422, -0.0006,  0.0340, -0.2779,  0.1925,  0.0102, -0.1850,\n",
      "           0.1201]],\n",
      "\n",
      "        [[ 0.1008, -0.0114, -0.1214, -0.0420, -0.0957,  0.0601, -0.0474,\n",
      "          -0.1321,  0.0321, -0.1375, -0.0039, -0.0380, -0.1312,  0.2840,\n",
      "          -0.0708, -0.1758,  0.2074,  0.1482, -0.2638,  0.0175,  0.0855,\n",
      "          -0.1862,  0.0073,  0.1886,  0.0728,  0.0831, -0.1029, -0.1767,\n",
      "          -0.0236, -0.0164,  0.0602,  0.1125, -0.0108,  0.1334,  0.1296,\n",
      "           0.0070,  0.1648,  0.2306,  0.0049,  0.2150, -0.0002, -0.0800,\n",
      "           0.1307,  0.3983, -0.1604,  0.1191,  0.5755,  0.1868,  0.0909,\n",
      "          -0.0361,  0.2375,  0.2724, -0.2540,  0.2405, -0.3045, -0.1086,\n",
      "          -0.2176, -0.1229, -0.1864, -0.3035, -0.0170, -0.0285, -0.1410,\n",
      "           0.1832]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0258,  0.1381, -0.1457, -0.0905,  0.0172, -0.0060,  0.2075,\n",
      "          -0.0309,  0.1936,  0.0714, -0.1245, -0.0914, -0.0774,  0.3177,\n",
      "          -0.2787, -0.2245,  0.2868,  0.1447, -0.4821, -0.1484, -0.0727,\n",
      "           0.3442,  0.1090,  0.3385,  0.4750, -0.0358,  0.0879, -0.2639,\n",
      "           0.0095,  0.3187,  0.0829, -0.2318, -0.0642, -0.1170,  0.2922,\n",
      "           0.1157,  0.2724,  0.2909,  0.2748,  0.0418, -0.2923, -0.0651,\n",
      "           0.0301,  0.1952, -0.1077, -0.2298, -0.0581, -0.0046, -0.1776,\n",
      "          -0.1001,  0.1115, -0.0363, -0.0849, -0.0837, -0.1171, -0.0992,\n",
      "           0.4443,  0.1449,  0.1002, -0.3025, -0.2516,  0.2503, -0.1342,\n",
      "           0.0155]],\n",
      "\n",
      "        [[-0.0471,  0.0113, -0.1076, -0.1881, -0.2442, -0.0055,  0.0448,\n",
      "          -0.0885,  0.0199,  0.2722,  0.0052, -0.0252,  0.0209,  0.1823,\n",
      "          -0.0856, -0.2951,  0.3866,  0.2035, -0.2326, -0.0259,  0.0789,\n",
      "          -0.0871, -0.0082,  0.0145,  0.1622,  0.0446,  0.0273, -0.0466,\n",
      "           0.0165,  0.2332,  0.2936, -0.0283,  0.0292,  0.0763,  0.3307,\n",
      "          -0.0467,  0.3257, -0.0853,  0.2119,  0.0575,  0.0070, -0.4056,\n",
      "           0.0863,  0.0629, -0.1172, -0.0571,  0.2068,  0.3878, -0.0803,\n",
      "          -0.0418,  0.5127,  0.2205, -0.1137, -0.0305, -0.1505, -0.4453,\n",
      "           0.0541, -0.0125,  0.0285, -0.2995,  0.1957,  0.0282, -0.1638,\n",
      "           0.1072]],\n",
      "\n",
      "        [[ 0.1004, -0.0077, -0.1330, -0.0378, -0.1189,  0.0476, -0.0451,\n",
      "          -0.1435,  0.0505, -0.1177,  0.0140, -0.0492, -0.1413,  0.3050,\n",
      "          -0.0643, -0.1787,  0.2254,  0.1585, -0.2807,  0.0048,  0.1095,\n",
      "          -0.2127,  0.0202,  0.2091,  0.0933,  0.0573, -0.1260, -0.1920,\n",
      "          -0.0321, -0.0215,  0.0623,  0.1262, -0.0110,  0.1042,  0.1425,\n",
      "           0.0364,  0.1715,  0.2558,  0.0161,  0.2335,  0.0032, -0.0758,\n",
      "           0.1460,  0.3784, -0.1821,  0.1109,  0.5981,  0.1952,  0.1005,\n",
      "          -0.0531,  0.2159,  0.2869, -0.2872,  0.2545, -0.3222, -0.1249,\n",
      "          -0.1982, -0.1448, -0.2170, -0.3256, -0.0067, -0.0181, -0.1317,\n",
      "           0.1706]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0364,  0.1588, -0.1627, -0.0977,  0.0136, -0.0073,  0.2152,\n",
      "          -0.0308,  0.2032,  0.0935, -0.0862, -0.1055, -0.0894,  0.3287,\n",
      "          -0.2711, -0.2299,  0.2962,  0.1506, -0.4867, -0.1624, -0.0667,\n",
      "           0.3255,  0.1137,  0.3518,  0.4912, -0.0378,  0.0832, -0.2610,\n",
      "           0.0073,  0.3023,  0.0783, -0.2219, -0.0687, -0.1231,  0.3018,\n",
      "           0.1310,  0.2856,  0.3086,  0.2847,  0.0449, -0.2996, -0.0579,\n",
      "           0.0460,  0.1948, -0.1135, -0.2281, -0.0452, -0.0010, -0.1697,\n",
      "          -0.1098,  0.1060, -0.0282, -0.0967, -0.0777, -0.1210, -0.1068,\n",
      "           0.4509,  0.1444,  0.0950, -0.3160, -0.2499,  0.2771, -0.1125,\n",
      "           0.0130]],\n",
      "\n",
      "        [[-0.0421,  0.0266, -0.1142, -0.1955, -0.2648, -0.0134,  0.0450,\n",
      "          -0.0951,  0.0328,  0.2983,  0.0227, -0.0366,  0.0124,  0.1922,\n",
      "          -0.0864, -0.3202,  0.3978,  0.2139, -0.2455, -0.0406,  0.0982,\n",
      "          -0.1038, -0.0018,  0.0322,  0.1830,  0.0308,  0.0184, -0.0533,\n",
      "           0.0140,  0.2109,  0.2803, -0.0189,  0.0268,  0.0567,  0.3490,\n",
      "          -0.0308,  0.3429, -0.0723,  0.2316,  0.0682,  0.0076, -0.3996,\n",
      "           0.0932,  0.0588, -0.1291, -0.0570,  0.2199,  0.3959, -0.0720,\n",
      "          -0.0536,  0.4970,  0.2294, -0.1400, -0.0260, -0.1594, -0.4594,\n",
      "           0.0667, -0.0209,  0.0227, -0.3185,  0.2036,  0.0458, -0.1428,\n",
      "           0.0958]],\n",
      "\n",
      "        [[ 0.1029, -0.0044, -0.1452, -0.0355, -0.1419,  0.0394, -0.0433,\n",
      "          -0.1550,  0.0716, -0.0975,  0.0307, -0.0608, -0.1548,  0.3273,\n",
      "          -0.0619, -0.1869,  0.2425,  0.1692, -0.2966, -0.0048,  0.1333,\n",
      "          -0.2385,  0.0347,  0.2305,  0.1117,  0.0344, -0.1482, -0.2055,\n",
      "          -0.0420, -0.0267,  0.0575,  0.1402, -0.0111,  0.0754,  0.1557,\n",
      "           0.0665,  0.1805,  0.2803,  0.0271,  0.2515,  0.0055, -0.0745,\n",
      "           0.1600,  0.3596, -0.2053,  0.1096,  0.6198,  0.2044,  0.1099,\n",
      "          -0.0703,  0.1945,  0.3012, -0.3205,  0.2696, -0.3400, -0.1424,\n",
      "          -0.1781, -0.1610, -0.2480, -0.3449,  0.0032, -0.0084, -0.1227,\n",
      "           0.1596]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0479,  0.1759, -0.1780, -0.1067,  0.0100, -0.0073,  0.2266,\n",
      "          -0.0282,  0.2143,  0.1155, -0.0477, -0.1189, -0.1038,  0.3392,\n",
      "          -0.2707, -0.2347,  0.3069,  0.1566, -0.4925, -0.1771, -0.0628,\n",
      "           0.3046,  0.1207,  0.3652,  0.5072, -0.0396,  0.0789, -0.2601,\n",
      "           0.0050,  0.2857,  0.0741, -0.2125, -0.0736, -0.1293,  0.3120,\n",
      "           0.1469,  0.2972,  0.3264,  0.2955,  0.0484, -0.3100, -0.0499,\n",
      "           0.0619,  0.1935, -0.1204, -0.2252, -0.0311,  0.0071, -0.1626,\n",
      "          -0.1196,  0.0999, -0.0188, -0.1091, -0.0703, -0.1251, -0.1145,\n",
      "           0.4583,  0.1449,  0.0899, -0.3297, -0.2507,  0.3039, -0.0910,\n",
      "           0.0112]],\n",
      "\n",
      "        [[-0.0369,  0.0379, -0.1205, -0.2060, -0.2850, -0.0139,  0.0475,\n",
      "          -0.0970,  0.0471,  0.3240,  0.0400, -0.0475,  0.0021,  0.2028,\n",
      "          -0.0890, -0.3427,  0.4098,  0.2251, -0.2588, -0.0551,  0.1143,\n",
      "          -0.1205,  0.0053,  0.0504,  0.2040,  0.0187,  0.0104, -0.0607,\n",
      "           0.0113,  0.1887,  0.2694, -0.0094,  0.0236,  0.0375,  0.3668,\n",
      "          -0.0150,  0.3593, -0.0591,  0.2516,  0.0795,  0.0068, -0.3941,\n",
      "           0.1001,  0.0542, -0.1421, -0.0543,  0.2335,  0.4059, -0.0644,\n",
      "          -0.0653,  0.4806,  0.2393, -0.1669, -0.0211, -0.1686, -0.4739,\n",
      "           0.0801, -0.0265,  0.0170, -0.3369,  0.2082,  0.0630, -0.1225,\n",
      "           0.0871]],\n",
      "\n",
      "        [[ 0.1065, -0.0020, -0.1587, -0.0367, -0.1658,  0.0359, -0.0410,\n",
      "          -0.1588,  0.0938, -0.0768,  0.0467, -0.0725, -0.1701,  0.3507,\n",
      "          -0.0628, -0.1931,  0.2606,  0.1805, -0.3126, -0.0134,  0.1560,\n",
      "          -0.2640,  0.0501,  0.2530,  0.1304,  0.0148, -0.1684, -0.2202,\n",
      "          -0.0525, -0.0320,  0.0554,  0.1546, -0.0119,  0.0465,  0.1683,\n",
      "           0.0969,  0.1911,  0.3056,  0.0381,  0.2701,  0.0071, -0.0760,\n",
      "           0.1752,  0.3396, -0.2297,  0.1162,  0.6404,  0.2143,  0.1197,\n",
      "          -0.0871,  0.1740,  0.3152, -0.3528,  0.2858, -0.3586, -0.1610,\n",
      "          -0.1583, -0.1706, -0.2777, -0.3626,  0.0118,  0.0006, -0.1150,\n",
      "           0.1506]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0602,  0.1925, -0.1923, -0.1171,  0.0064, -0.0061,  0.2400,\n",
      "          -0.0248,  0.2265,  0.1378, -0.0093, -0.1319, -0.1199,  0.3496,\n",
      "          -0.2763, -0.2403,  0.3189,  0.1627, -0.4996, -0.1924, -0.0607,\n",
      "           0.2824,  0.1294,  0.3788,  0.5230, -0.0408,  0.0751, -0.2607,\n",
      "           0.0025,  0.2691,  0.0702, -0.2040, -0.0789, -0.1356,  0.3227,\n",
      "           0.1631,  0.3092,  0.3443,  0.3073,  0.0520, -0.3235, -0.0420,\n",
      "           0.0779,  0.1918, -0.1282, -0.2213, -0.0157,  0.0181, -0.1561,\n",
      "          -0.1296,  0.0939, -0.0079, -0.1222, -0.0616, -0.1293, -0.1223,\n",
      "           0.4667,  0.1451,  0.0848, -0.3437, -0.2527,  0.3306, -0.0701,\n",
      "           0.0103]],\n",
      "\n",
      "        [[-0.0317,  0.0486, -0.1269, -0.2183, -0.3047, -0.0087,  0.0518,\n",
      "          -0.0969,  0.0624,  0.3498,  0.0572, -0.0584, -0.0097,  0.2140,\n",
      "          -0.0931, -0.3670,  0.4226,  0.2373, -0.2729, -0.0701,  0.1278,\n",
      "          -0.1370,  0.0128,  0.0692,  0.2256,  0.0082,  0.0032, -0.0691,\n",
      "           0.0086,  0.1666,  0.2592,  0.0001,  0.0195,  0.0189,  0.3843,\n",
      "           0.0008,  0.3769, -0.0460,  0.2726,  0.0915,  0.0042, -0.3893,\n",
      "           0.1072,  0.0495, -0.1564, -0.0498,  0.2477,  0.4171, -0.0573,\n",
      "          -0.0769,  0.4641,  0.2501, -0.1941, -0.0158, -0.1783, -0.4886,\n",
      "           0.0943, -0.0315,  0.0112, -0.3553,  0.2117,  0.0801, -0.1029,\n",
      "           0.0815]],\n",
      "\n",
      "        [[ 0.1113,  0.0002, -0.1733, -0.0402, -0.1901,  0.0363, -0.0383,\n",
      "          -0.1592,  0.1172, -0.0557,  0.0622, -0.0848, -0.1866,  0.3747,\n",
      "          -0.0660, -0.1998,  0.2798,  0.1923, -0.3297, -0.0223,  0.1781,\n",
      "          -0.2891,  0.0665,  0.2766,  0.1499, -0.0019, -0.1874, -0.2359,\n",
      "          -0.0639, -0.0374,  0.0546,  0.1696, -0.0133,  0.0180,  0.1810,\n",
      "           0.1282,  0.2036,  0.3318,  0.0496,  0.2891,  0.0080, -0.0798,\n",
      "           0.1913,  0.3188, -0.2550,  0.1282,  0.6599,  0.2248,  0.1298,\n",
      "          -0.1037,  0.1547,  0.3291, -0.3844,  0.3028, -0.3778, -0.1806,\n",
      "          -0.1392, -0.1771, -0.3063, -0.3792,  0.0201,  0.0091, -0.1083,\n",
      "           0.1433]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0730,  0.2089, -0.2059, -0.1282,  0.0028, -0.0041,  0.2547,\n",
      "          -0.0211,  0.2395,  0.1607,  0.0279, -0.1445, -0.1372,  0.3604,\n",
      "          -0.2861, -0.2465,  0.3320,  0.1689, -0.5082, -0.2083, -0.0597,\n",
      "           0.2594,  0.1396,  0.3923,  0.5386, -0.0410,  0.0718, -0.2626,\n",
      "          -0.0002,  0.2524,  0.0665, -0.1961, -0.0847, -0.1417,  0.3337,\n",
      "           0.1797,  0.3218,  0.3625,  0.3203,  0.0560, -0.3397, -0.0349,\n",
      "           0.0940,  0.1900, -0.1368, -0.2168,  0.0009,  0.0312, -0.1505,\n",
      "          -0.1399,  0.0889,  0.0043, -0.1360, -0.0521, -0.1339, -0.1303,\n",
      "           0.4763,  0.1432,  0.0797, -0.3582, -0.2529,  0.3574, -0.0498,\n",
      "           0.0101]],\n",
      "\n",
      "        [[-0.0265,  0.0597, -0.1333, -0.2318, -0.3239,  0.0022,  0.0574,\n",
      "          -0.0957,  0.0785,  0.3757,  0.0741, -0.0694, -0.0224,  0.2261,\n",
      "          -0.0983, -0.3937,  0.4361,  0.2504, -0.2876, -0.0857,  0.1402,\n",
      "          -0.1533,  0.0207,  0.0886,  0.2478,  0.0007, -0.0034, -0.0782,\n",
      "           0.0057,  0.1448,  0.2503,  0.0098,  0.0146,  0.0006,  0.4017,\n",
      "           0.0167,  0.3953, -0.0329,  0.2946,  0.1043, -0.0000, -0.3858,\n",
      "           0.1145,  0.0446, -0.1719, -0.0440,  0.2625,  0.4292, -0.0511,\n",
      "          -0.0889,  0.4483,  0.2619, -0.2217, -0.0102, -0.1886, -0.5036,\n",
      "           0.1095, -0.0382,  0.0054, -0.3735,  0.2177,  0.0973, -0.0842,\n",
      "           0.0784]],\n",
      "\n",
      "        [[ 0.1171,  0.0025, -0.1889, -0.0452, -0.2148,  0.0405, -0.0352,\n",
      "          -0.1578,  0.1414, -0.0342,  0.0774, -0.0979, -0.2038,  0.3992,\n",
      "          -0.0710, -0.2075,  0.3001,  0.2048, -0.3476, -0.0312,  0.2004,\n",
      "          -0.3139,  0.0838,  0.3010,  0.1701, -0.0141, -0.2060, -0.2525,\n",
      "          -0.0763, -0.0427,  0.0556,  0.1852, -0.0153, -0.0104,  0.1940,\n",
      "           0.1605,  0.2171,  0.3587,  0.0617,  0.3085,  0.0083, -0.0856,\n",
      "           0.2082,  0.2975, -0.2812,  0.1439,  0.6783,  0.2359,  0.1400,\n",
      "          -0.1207,  0.1369,  0.3429, -0.4149,  0.3206, -0.3974, -0.2011,\n",
      "          -0.1204, -0.1831, -0.3341, -0.3950,  0.0291,  0.0172, -0.1025,\n",
      "           0.1375]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.0864,  0.2242, -0.2190, -0.1400, -0.0008, -0.0016,  0.2704,\n",
      "          -0.0172,  0.2530,  0.1840,  0.0632, -0.1566, -0.1553,  0.3717,\n",
      "          -0.2989, -0.2532,  0.3462,  0.1754, -0.5176, -0.2248, -0.0599,\n",
      "           0.2367,  0.1508,  0.4060,  0.5542, -0.0400,  0.0692, -0.2664,\n",
      "          -0.0031,  0.2358,  0.0628, -0.1889, -0.0909, -0.1477,  0.3450,\n",
      "           0.1970,  0.3350,  0.3809,  0.3346,  0.0603, -0.3576, -0.0299,\n",
      "           0.1105,  0.1884, -0.1464, -0.2116,  0.0186,  0.0461, -0.1457,\n",
      "          -0.1505,  0.0852,  0.0182, -0.1507, -0.0419, -0.1387, -0.1384,\n",
      "           0.4870,  0.1379,  0.0746, -0.3733, -0.2517,  0.3842, -0.0305,\n",
      "           0.0110]],\n",
      "\n",
      "        [[-0.0213,  0.0691, -0.1399, -0.2463, -0.3426,  0.0158,  0.0642,\n",
      "          -0.0949,  0.0951,  0.4019,  0.0908, -0.0803, -0.0360,  0.2392,\n",
      "          -0.1042, -0.4210,  0.4502,  0.2643, -0.3025, -0.1015,  0.1515,\n",
      "          -0.1690,  0.0288,  0.1085,  0.2708, -0.0029, -0.0089, -0.0886,\n",
      "           0.0027,  0.1232,  0.2401,  0.0195,  0.0090, -0.0167,  0.4191,\n",
      "           0.0330,  0.4142, -0.0199,  0.3179,  0.1180, -0.0055, -0.3846,\n",
      "           0.1219,  0.0398, -0.1887, -0.0368,  0.2779,  0.4418, -0.0453,\n",
      "          -0.1009,  0.4338,  0.2745, -0.2497, -0.0043, -0.1997, -0.5188,\n",
      "           0.1255, -0.0493, -0.0004, -0.3918,  0.2256,  0.1149, -0.0665,\n",
      "           0.0787]],\n",
      "\n",
      "        [[ 0.1238,  0.0044, -0.2053, -0.0507, -0.2396,  0.0466, -0.0318,\n",
      "          -0.1570,  0.1663, -0.0116,  0.0927, -0.1116, -0.2215,  0.4244,\n",
      "          -0.0773, -0.2170,  0.3213,  0.2181, -0.3661, -0.0398,  0.2230,\n",
      "          -0.3383,  0.1023,  0.3262,  0.1909, -0.0204, -0.2235, -0.2702,\n",
      "          -0.0896, -0.0481,  0.0557,  0.2012, -0.0175, -0.0374,  0.2069,\n",
      "           0.1940,  0.2313,  0.3862,  0.0745,  0.3280,  0.0082, -0.0934,\n",
      "           0.2255,  0.2761, -0.3081,  0.1631,  0.6958,  0.2475,  0.1506,\n",
      "          -0.1378,  0.1209,  0.3568, -0.4446,  0.3391, -0.4175, -0.2223,\n",
      "          -0.1023, -0.1940, -0.3610, -0.4099,  0.0389,  0.0251, -0.0971,\n",
      "           0.1335]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1002,  0.2425, -0.2318, -0.1523, -0.0044,  0.0013,  0.2867,\n",
      "          -0.0138,  0.2671,  0.2078,  0.0973, -0.1683, -0.1740,  0.3834,\n",
      "          -0.3141, -0.2607,  0.3614,  0.1820, -0.5275, -0.2417, -0.0609,\n",
      "           0.2147,  0.1628,  0.4199,  0.5698, -0.0382,  0.0671, -0.2714,\n",
      "          -0.0062,  0.2192,  0.0591, -0.1823, -0.0977, -0.1530,  0.3567,\n",
      "           0.2146,  0.3488,  0.3994,  0.3500,  0.0650, -0.3769, -0.0269,\n",
      "           0.1275,  0.1875, -0.1571, -0.2058,  0.0375,  0.0626, -0.1416,\n",
      "          -0.1614,  0.0831,  0.0337, -0.1663, -0.0309, -0.1439, -0.1467,\n",
      "           0.4989,  0.1303,  0.0695, -0.3890, -0.2486,  0.4110, -0.0125,\n",
      "           0.0128]],\n",
      "\n",
      "        [[-0.0162,  0.0826, -0.1466, -0.2617, -0.3607,  0.0315,  0.0720,\n",
      "          -0.0949,  0.1123,  0.4282,  0.1076, -0.0914, -0.0505,  0.2529,\n",
      "          -0.1108, -0.4493,  0.4651,  0.2790, -0.3177, -0.1180,  0.1621,\n",
      "          -0.1842,  0.0371,  0.1293,  0.2942, -0.0029, -0.0137, -0.1003,\n",
      "          -0.0004,  0.1022,  0.2299,  0.0293,  0.0027, -0.0328,  0.4365,\n",
      "           0.0497,  0.4335, -0.0070,  0.3424,  0.1327, -0.0122, -0.3853,\n",
      "           0.1295,  0.0354, -0.2067, -0.0286,  0.2940,  0.4549, -0.0399,\n",
      "          -0.1135,  0.4212,  0.2881, -0.2782,  0.0017, -0.2114, -0.5340,\n",
      "           0.1424, -0.0637, -0.0062, -0.4102,  0.2356,  0.1328, -0.0500,\n",
      "           0.0820]],\n",
      "\n",
      "        [[ 0.1315,  0.0072, -0.2225, -0.0569, -0.2642,  0.0543, -0.0282,\n",
      "          -0.1578,  0.1916,  0.0122,  0.1082, -0.1261, -0.2396,  0.4496,\n",
      "          -0.0847, -0.2282,  0.3432,  0.2323, -0.3852, -0.0489,  0.2460,\n",
      "          -0.3622,  0.1217,  0.3521,  0.2118, -0.0213, -0.2406, -0.2889,\n",
      "          -0.1038, -0.0534,  0.0562,  0.2178, -0.0202, -0.0626,  0.2199,\n",
      "           0.2287,  0.2458,  0.4140,  0.0882,  0.3476,  0.0077, -0.1028,\n",
      "           0.2433,  0.2556, -0.3354,  0.1848,  0.7122,  0.2595,  0.1616,\n",
      "          -0.1553,  0.1068,  0.3707, -0.4735,  0.3582, -0.4380, -0.2442,\n",
      "          -0.0848, -0.2093, -0.3867, -0.4241,  0.0496,  0.0329, -0.0924,\n",
      "           0.1309]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1144,  0.2633, -0.2443, -0.1652, -0.0079,  0.0043,  0.3036,\n",
      "          -0.0112,  0.2818,  0.2320,  0.1308, -0.1795, -0.1931,  0.3955,\n",
      "          -0.3308, -0.2688,  0.3774,  0.1887, -0.5378, -0.2587, -0.0633,\n",
      "           0.1932,  0.1755,  0.4341,  0.5853, -0.0359,  0.0653, -0.2776,\n",
      "          -0.0095,  0.2027,  0.0553, -0.1765, -0.1052, -0.1573,  0.3687,\n",
      "           0.2325,  0.3634,  0.4181,  0.3664,  0.0699, -0.3972, -0.0244,\n",
      "           0.1450,  0.1873, -0.1687, -0.1994,  0.0578,  0.0805, -0.1383,\n",
      "          -0.1728,  0.0824,  0.0510, -0.1827, -0.0191, -0.1495, -0.1552,\n",
      "           0.5118,  0.1210,  0.0643, -0.4055, -0.2437,  0.4377,  0.0039,\n",
      "           0.0155]],\n",
      "\n",
      "        [[-0.0111,  0.0996, -0.1535, -0.2780, -0.3783,  0.0488,  0.0805,\n",
      "          -0.0964,  0.1301,  0.4544,  0.1249, -0.1024, -0.0658,  0.2674,\n",
      "          -0.1178, -0.4783,  0.4805,  0.2945, -0.3330, -0.1353,  0.1713,\n",
      "          -0.1990,  0.0457,  0.1509,  0.3182, -0.0003, -0.0179, -0.1131,\n",
      "          -0.0037,  0.0818,  0.2183,  0.0392, -0.0045, -0.0475,  0.4541,\n",
      "           0.0667,  0.4530,  0.0058,  0.3680,  0.1484, -0.0201, -0.3868,\n",
      "           0.1374,  0.0313, -0.2261, -0.0194,  0.3106,  0.4682, -0.0353,\n",
      "          -0.1266,  0.4104,  0.3025, -0.3066,  0.0081, -0.2240, -0.5494,\n",
      "           0.1601, -0.0809, -0.0121, -0.4286,  0.2473,  0.1511, -0.0352,\n",
      "           0.0882]],\n",
      "\n",
      "        [[ 0.1400,  0.0107, -0.2404, -0.0636, -0.2885,  0.0633, -0.0245,\n",
      "          -0.1609,  0.2173,  0.0371,  0.1243, -0.1415, -0.2580,  0.4748,\n",
      "          -0.0933, -0.2405,  0.3659,  0.2474, -0.4047, -0.0587,  0.2689,\n",
      "          -0.3859,  0.1421,  0.3786,  0.2327, -0.0179, -0.2578, -0.3082,\n",
      "          -0.1188, -0.0587,  0.0555,  0.2351, -0.0234, -0.0858,  0.2327,\n",
      "           0.2643,  0.2605,  0.4420,  0.1028,  0.3670,  0.0069, -0.1135,\n",
      "           0.2615,  0.2358, -0.3629,  0.2086,  0.7276,  0.2720,  0.1725,\n",
      "          -0.1735,  0.0946,  0.3845, -0.5011,  0.3778, -0.4587, -0.2667,\n",
      "          -0.0676, -0.2278, -0.4114, -0.4372,  0.0609,  0.0406, -0.0885,\n",
      "           0.1299]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1290,  0.2852, -0.2567, -0.1784, -0.0115,  0.0077,  0.3207,\n",
      "          -0.0100,  0.2973,  0.2564,  0.1639, -0.1903, -0.2125,  0.4080,\n",
      "          -0.3485, -0.2776,  0.3942,  0.1958, -0.5481, -0.2757, -0.0675,\n",
      "           0.1719,  0.1889,  0.4485,  0.6008, -0.0333,  0.0639, -0.2846,\n",
      "          -0.0131,  0.1865,  0.0513, -0.1714, -0.1134, -0.1602,  0.3810,\n",
      "           0.2506,  0.3786,  0.4370,  0.3837,  0.0753, -0.4184, -0.0225,\n",
      "           0.1631,  0.1875, -0.1814, -0.1921,  0.0797,  0.0997, -0.1357,\n",
      "          -0.1847,  0.0835,  0.0702, -0.2001, -0.0065, -0.1553, -0.1642,\n",
      "           0.5257,  0.1106,  0.0589, -0.4228, -0.2378,  0.4642,  0.0184,\n",
      "           0.0189]],\n",
      "\n",
      "        [[-0.0060,  0.1194, -0.1606, -0.2949, -0.3954,  0.0674,  0.0897,\n",
      "          -0.0997,  0.1487,  0.4803,  0.1428, -0.1134, -0.0818,  0.2825,\n",
      "          -0.1251, -0.5073,  0.4966,  0.3107, -0.3482, -0.1535,  0.1780,\n",
      "          -0.2137,  0.0547,  0.1734,  0.3428,  0.0042, -0.0217, -0.1270,\n",
      "          -0.0071,  0.0621,  0.2051,  0.0491, -0.0128, -0.0602,  0.4719,\n",
      "           0.0840,  0.4726,  0.0185,  0.3944,  0.1652, -0.0290, -0.3890,\n",
      "           0.1456,  0.0273, -0.2466, -0.0089,  0.3279,  0.4817, -0.0310,\n",
      "          -0.1404,  0.4018,  0.3178, -0.3352,  0.0147, -0.2373, -0.5650,\n",
      "           0.1786, -0.1003, -0.0182, -0.4473,  0.2602,  0.1699, -0.0224,\n",
      "           0.0969]],\n",
      "\n",
      "        [[ 0.1494,  0.0148, -0.2592, -0.0708, -0.3124,  0.0735, -0.0205,\n",
      "          -0.1668,  0.2432,  0.0634,  0.1412, -0.1575, -0.2767,  0.4999,\n",
      "          -0.1027, -0.2536,  0.3891,  0.2634, -0.4246, -0.0694,  0.2904,\n",
      "          -0.4095,  0.1637,  0.4056,  0.2538, -0.0113, -0.2754, -0.3282,\n",
      "          -0.1348, -0.0640,  0.0531,  0.2528, -0.0273, -0.1060,  0.2457,\n",
      "           0.3004,  0.2753,  0.4700,  0.1183,  0.3864,  0.0060, -0.1253,\n",
      "           0.2801,  0.2166, -0.3904,  0.2348,  0.7423,  0.2849,  0.1837,\n",
      "          -0.1922,  0.0844,  0.3980, -0.5276,  0.3978, -0.4796, -0.2899,\n",
      "          -0.0508, -0.2491, -0.4350, -0.4499,  0.0731,  0.0483, -0.0857,\n",
      "           0.1304]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1439,  0.3084, -0.2690, -0.1921, -0.0152,  0.0112,  0.3379,\n",
      "          -0.0102,  0.3137,  0.2812,  0.1966, -0.2007, -0.2321,  0.4210,\n",
      "          -0.3671, -0.2869,  0.4116,  0.2031, -0.5585, -0.2931, -0.0732,\n",
      "           0.1506,  0.2029,  0.4632,  0.6163, -0.0307,  0.0626, -0.2927,\n",
      "          -0.0170,  0.1706,  0.0474, -0.1669, -0.1227, -0.1619,  0.3934,\n",
      "           0.2688,  0.3947,  0.4563,  0.4020,  0.0810, -0.4401, -0.0217,\n",
      "           0.1817,  0.1884, -0.1952, -0.1838,  0.1034,  0.1199, -0.1336,\n",
      "          -0.1972,  0.0869,  0.0914, -0.2184,  0.0072, -0.1616, -0.1737,\n",
      "           0.5405,  0.0992,  0.0533, -0.4411, -0.2307,  0.4905,  0.0304,\n",
      "           0.0228]],\n",
      "\n",
      "        [[-0.0009,  0.1419, -0.1681, -0.3125, -0.4121,  0.0872,  0.0996,\n",
      "          -0.1043,  0.1681,  0.5058,  0.1615, -0.1244, -0.0985,  0.2983,\n",
      "          -0.1329, -0.5359,  0.5132,  0.3278, -0.3635, -0.1726,  0.1830,\n",
      "          -0.2284,  0.0640,  0.1970,  0.3682,  0.0102, -0.0256, -0.1419,\n",
      "          -0.0108,  0.0430,  0.1915,  0.0593, -0.0223, -0.0712,  0.4899,\n",
      "           0.1015,  0.4923,  0.0314,  0.4218,  0.1832, -0.0390, -0.3923,\n",
      "           0.1541,  0.0236, -0.2683,  0.0029,  0.3460,  0.4955, -0.0271,\n",
      "          -0.1550,  0.3962,  0.3340, -0.3639,  0.0217, -0.2517, -0.5809,\n",
      "           0.1978, -0.1216, -0.0246, -0.4666,  0.2744,  0.1890, -0.0121,\n",
      "           0.1078]],\n",
      "\n",
      "        [[ 0.1596,  0.0194, -0.2787, -0.0784, -0.3359,  0.0852, -0.0164,\n",
      "          -0.1750,  0.2692,  0.0910,  0.1588, -0.1744, -0.2957,  0.5248,\n",
      "          -0.1131, -0.2675,  0.4129,  0.2802, -0.4450, -0.0809,  0.3112,\n",
      "          -0.4328,  0.1864,  0.4332,  0.2750, -0.0021, -0.2935, -0.3489,\n",
      "          -0.1517, -0.0692,  0.0502,  0.2712, -0.0318, -0.1237,  0.2591,\n",
      "           0.3368,  0.2900,  0.4979,  0.1350,  0.4056,  0.0048, -0.1382,\n",
      "           0.2991,  0.1979, -0.4176,  0.2629,  0.7561,  0.2983,  0.1954,\n",
      "          -0.2115,  0.0766,  0.4112, -0.5531,  0.4182, -0.5006, -0.3136,\n",
      "          -0.0343, -0.2728, -0.4576, -0.4626,  0.0861,  0.0560, -0.0842,\n",
      "           0.1323]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1593,  0.3324, -0.2816, -0.2059, -0.0191,  0.0148,  0.3553,\n",
      "          -0.0112,  0.3312,  0.3063,  0.2291, -0.2108, -0.2519,  0.4343,\n",
      "          -0.3865, -0.2968,  0.4300,  0.2106, -0.5693, -0.3107, -0.0799,\n",
      "           0.1289,  0.2176,  0.4781,  0.6320, -0.0280,  0.0613, -0.3020,\n",
      "          -0.0212,  0.1552,  0.0442, -0.1628, -0.1330, -0.1622,  0.4059,\n",
      "           0.2868,  0.4119,  0.4759,  0.4216,  0.0871, -0.4622, -0.0220,\n",
      "           0.2011,  0.1901, -0.2103, -0.1747,  0.1289,  0.1412, -0.1322,\n",
      "          -0.2103,  0.0930,  0.1145, -0.2376,  0.0218, -0.1684, -0.1836,\n",
      "           0.5560,  0.0869,  0.0474, -0.4597, -0.2225,  0.5164,  0.0395,\n",
      "           0.0273]],\n",
      "\n",
      "        [[ 0.0043,  0.1669, -0.1760, -0.3305, -0.4284,  0.1080,  0.1100,\n",
      "          -0.1098,  0.1885,  0.5307,  0.1810, -0.1353, -0.1160,  0.3145,\n",
      "          -0.1410, -0.5639,  0.5305,  0.3454, -0.3790, -0.1924,  0.1870,\n",
      "          -0.2431,  0.0738,  0.2215,  0.3940,  0.0181, -0.0295, -0.1583,\n",
      "          -0.0147,  0.0247,  0.1827,  0.0697, -0.0330, -0.0805,  0.5080,\n",
      "           0.1192,  0.5120,  0.0443,  0.4500,  0.2022, -0.0501, -0.3966,\n",
      "           0.1630,  0.0203, -0.2912,  0.0158,  0.3649,  0.5095, -0.0236,\n",
      "          -0.1705,  0.3939,  0.3511, -0.3921,  0.0290, -0.2670, -0.5969,\n",
      "           0.2174, -0.1448, -0.0314, -0.4863,  0.2897,  0.2086, -0.0046,\n",
      "           0.1203]],\n",
      "\n",
      "        [[ 0.1705,  0.0245, -0.2990, -0.0861, -0.3594,  0.0983, -0.0121,\n",
      "          -0.1852,  0.2952,  0.1198,  0.1773, -0.1920, -0.3147,  0.5493,\n",
      "          -0.1241, -0.2821,  0.4368,  0.2979, -0.4660, -0.0932,  0.3312,\n",
      "          -0.4560,  0.2100,  0.4612,  0.2959,  0.0099, -0.3123, -0.3706,\n",
      "          -0.1694, -0.0746,  0.0518,  0.2899, -0.0370, -0.1391,  0.2731,\n",
      "           0.3734,  0.3045,  0.5254,  0.1528,  0.4247,  0.0036, -0.1520,\n",
      "           0.3184,  0.1805, -0.4444,  0.2924,  0.7693,  0.3121,  0.2072,\n",
      "          -0.2313,  0.0712,  0.4241, -0.5776,  0.4390, -0.5217, -0.3379,\n",
      "          -0.0187, -0.2987, -0.4791, -0.4761,  0.0997,  0.0638, -0.0841,\n",
      "           0.1352]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1753,  0.3573, -0.2946, -0.2201, -0.0232,  0.0186,  0.3729,\n",
      "          -0.0131,  0.3496,  0.3315,  0.2611, -0.2208, -0.2717,  0.4478,\n",
      "          -0.4063, -0.3072,  0.4491,  0.2184, -0.5803, -0.3287, -0.0874,\n",
      "           0.1067,  0.2330,  0.4932,  0.6478, -0.0253,  0.0601, -0.3126,\n",
      "          -0.0256,  0.1404,  0.0419, -0.1591, -0.1445, -0.1617,  0.4186,\n",
      "           0.3046,  0.4300,  0.4959,  0.4425,  0.0937, -0.4846, -0.0238,\n",
      "           0.2211,  0.1931, -0.2268, -0.1647,  0.1563,  0.1633, -0.1312,\n",
      "          -0.2243,  0.1018,  0.1396, -0.2576,  0.0376, -0.1756, -0.1941,\n",
      "           0.5722,  0.0736,  0.0409, -0.4787, -0.2131,  0.5419,  0.0454,\n",
      "           0.0322]],\n",
      "\n",
      "        [[ 0.0096,  0.1940, -0.1844, -0.3488, -0.4443,  0.1295,  0.1213,\n",
      "          -0.1161,  0.2100,  0.5547,  0.2013, -0.1463, -0.1341,  0.3312,\n",
      "          -0.1496, -0.5910,  0.5482,  0.3636, -0.3949, -0.2127,  0.1907,\n",
      "          -0.2578,  0.0840,  0.2471,  0.4204,  0.0274, -0.0338, -0.1758,\n",
      "          -0.0191,  0.0070,  0.1785,  0.0804, -0.0448, -0.0887,  0.5263,\n",
      "           0.1371,  0.5315,  0.0575,  0.4788,  0.2224, -0.0622, -0.4023,\n",
      "           0.1723,  0.0176, -0.3153,  0.0302,  0.3846,  0.5237, -0.0202,\n",
      "          -0.1871,  0.3949,  0.3690, -0.4200,  0.0367, -0.2833, -0.6131,\n",
      "           0.2376, -0.1698, -0.0388, -0.5063,  0.3060,  0.2287,  0.0002,\n",
      "           0.1345]],\n",
      "\n",
      "        [[ 0.1822,  0.0302, -0.3200, -0.0940, -0.3827,  0.1129, -0.0076,\n",
      "          -0.1968,  0.3212,  0.1497,  0.1969, -0.2105, -0.3336,  0.5732,\n",
      "          -0.1359, -0.2973,  0.4610,  0.3164, -0.4873, -0.1065,  0.3511,\n",
      "          -0.4791,  0.2345,  0.4897,  0.3172,  0.0240, -0.3316, -0.3932,\n",
      "          -0.1879, -0.0800,  0.0573,  0.3091, -0.0429, -0.1530,  0.2876,\n",
      "           0.4098,  0.3186,  0.5526,  0.1718,  0.4436,  0.0022, -0.1667,\n",
      "           0.3381,  0.1652, -0.4706,  0.3233,  0.7818,  0.3263,  0.2194,\n",
      "          -0.2516,  0.0684,  0.4366, -0.6014,  0.4601, -0.5427, -0.3628,\n",
      "          -0.0037, -0.3262, -0.4996, -0.4903,  0.1139,  0.0717, -0.0853,\n",
      "           0.1394]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.1917,  0.3827, -0.3080, -0.2343, -0.0276,  0.0225,  0.3907,\n",
      "          -0.0154,  0.3691,  0.3569,  0.2926, -0.2305, -0.2915,  0.4615,\n",
      "          -0.4265, -0.3182,  0.4689,  0.2265, -0.5914, -0.3473, -0.0952,\n",
      "           0.0839,  0.2492,  0.5086,  0.6636, -0.0225,  0.0589, -0.3240,\n",
      "          -0.0304,  0.1264,  0.0403, -0.1557, -0.1574, -0.1609,  0.4316,\n",
      "           0.3225,  0.4492,  0.5162,  0.4647,  0.1008, -0.5072, -0.0277,\n",
      "           0.2416,  0.1979, -0.2452, -0.1538,  0.1859,  0.1863, -0.1304,\n",
      "          -0.2392,  0.1134,  0.1665, -0.2787,  0.0547, -0.1834, -0.2052,\n",
      "           0.5891,  0.0594,  0.0339, -0.4980, -0.2025,  0.5668,  0.0483,\n",
      "           0.0376]],\n",
      "\n",
      "        [[ 0.0150,  0.2230, -0.1934, -0.3674, -0.4598,  0.1514,  0.1335,\n",
      "          -0.1229,  0.2325,  0.5779,  0.2223, -0.1573, -0.1530,  0.3483,\n",
      "          -0.1586, -0.6169,  0.5664,  0.3825, -0.4109, -0.2336,  0.1952,\n",
      "          -0.2727,  0.0946,  0.2738,  0.4474,  0.0380, -0.0383, -0.1944,\n",
      "          -0.0238, -0.0098,  0.1783,  0.0913, -0.0576, -0.0969,  0.5447,\n",
      "           0.1553,  0.5508,  0.0711,  0.5080,  0.2438, -0.0753, -0.4095,\n",
      "           0.1820,  0.0158, -0.3407,  0.0460,  0.4051,  0.5381, -0.0165,\n",
      "          -0.2048,  0.3992,  0.3877, -0.4476,  0.0449, -0.3004, -0.6296,\n",
      "           0.2586, -0.1962, -0.0468, -0.5265,  0.3233,  0.2492,  0.0021,\n",
      "           0.1501]],\n",
      "\n",
      "        [[ 0.1946,  0.0365, -0.3417, -0.1018, -0.4058,  0.1289, -0.0028,\n",
      "          -0.2098,  0.3474,  0.1808,  0.2177, -0.2299, -0.3525,  0.5964,\n",
      "          -0.1485, -0.3131,  0.4852,  0.3359, -0.5087, -0.1209,  0.3717,\n",
      "          -0.5020,  0.2599,  0.5182,  0.3392,  0.0400, -0.3513, -0.4166,\n",
      "          -0.2072, -0.0855,  0.0661,  0.3287, -0.0495, -0.1672,  0.3026,\n",
      "           0.4457,  0.3324,  0.5791,  0.1921,  0.4622,  0.0007, -0.1821,\n",
      "           0.3580,  0.1535, -0.4962,  0.3551,  0.7937,  0.3411,  0.2323,\n",
      "          -0.2724,  0.0679,  0.4487, -0.6244,  0.4816, -0.5635, -0.3882,\n",
      "           0.0109, -0.3551, -0.5191, -0.5050,  0.1289,  0.0796, -0.0878,\n",
      "           0.1449]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.2088,  0.4085, -0.3219, -0.2487, -0.0324,  0.0265,  0.4089,\n",
      "          -0.0183,  0.3895,  0.3824,  0.3233, -0.2403, -0.3114,  0.4756,\n",
      "          -0.4469, -0.3297,  0.4894,  0.2350, -0.6027, -0.3664, -0.1028,\n",
      "           0.0603,  0.2663,  0.5244,  0.6793, -0.0197,  0.0577, -0.3361,\n",
      "          -0.0355,  0.1133,  0.0395, -0.1526, -0.1718, -0.1602,  0.4450,\n",
      "           0.3403,  0.4692,  0.5369,  0.4881,  0.1085, -0.5298, -0.0339,\n",
      "           0.2628,  0.2047, -0.2655, -0.1418,  0.2174,  0.2099, -0.1298,\n",
      "          -0.2551,  0.1275,  0.1952, -0.3007,  0.0732, -0.1919, -0.2170,\n",
      "           0.6068,  0.0442,  0.0260, -0.5174, -0.1907,  0.5912,  0.0481,\n",
      "           0.0435]],\n",
      "\n",
      "        [[ 0.0205,  0.2538, -0.2031, -0.3862, -0.4748,  0.1734,  0.1466,\n",
      "          -0.1302,  0.2562,  0.6001,  0.2440, -0.1684, -0.1726,  0.3658,\n",
      "          -0.1680, -0.6415,  0.5849,  0.4021, -0.4271, -0.2550,  0.2014,\n",
      "          -0.2879,  0.1058,  0.3014,  0.4749,  0.0497, -0.0431, -0.2139,\n",
      "          -0.0291, -0.0257,  0.1815,  0.1025, -0.0716, -0.1056,  0.5634,\n",
      "           0.1739,  0.5696,  0.0852,  0.5375,  0.2662, -0.0894, -0.4183,\n",
      "           0.1920,  0.0151, -0.3673,  0.0633,  0.4264,  0.5527, -0.0126,\n",
      "          -0.2238,  0.4065,  0.4072, -0.4746,  0.0536, -0.3183, -0.6462,\n",
      "           0.2804, -0.2238, -0.0555, -0.5468,  0.3414,  0.2700,  0.0016,\n",
      "           0.1671]],\n",
      "\n",
      "        [[ 0.2077,  0.0435, -0.3640, -0.1097, -0.4286,  0.1463,  0.0022,\n",
      "          -0.2239,  0.3738,  0.2127,  0.2397, -0.2503, -0.3711,  0.6186,\n",
      "          -0.1617, -0.3295,  0.5095,  0.3561, -0.5302, -0.1365,  0.3937,\n",
      "          -0.5248,  0.2860,  0.5468,  0.3621,  0.0577, -0.3712, -0.4408,\n",
      "          -0.2273, -0.0912,  0.0775,  0.3486, -0.0567, -0.1824,  0.3182,\n",
      "           0.4810,  0.3458,  0.6049,  0.2136,  0.4806, -0.0009, -0.1981,\n",
      "           0.3783,  0.1460, -0.5211,  0.3876,  0.8050,  0.3563,  0.2462,\n",
      "          -0.2936,  0.0696,  0.4606, -0.6467,  0.5032, -0.5841, -0.4140,\n",
      "           0.0253, -0.3849, -0.5376, -0.5203,  0.1445,  0.0877, -0.0916,\n",
      "           0.1518]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.2265,  0.4346, -0.3363, -0.2632, -0.0376,  0.0306,  0.4272,\n",
      "          -0.0217,  0.4107,  0.4081,  0.3531, -0.2502, -0.3313,  0.4900,\n",
      "          -0.4675, -0.3419,  0.5104,  0.2441, -0.6141, -0.3861, -0.1097,\n",
      "           0.0359,  0.2841,  0.5406,  0.6951, -0.0171,  0.0565, -0.3491,\n",
      "          -0.0411,  0.1013,  0.0393, -0.1498, -0.1879, -0.1601,  0.4589,\n",
      "           0.3582,  0.4901,  0.5579,  0.5126,  0.1170, -0.5523, -0.0423,\n",
      "           0.2846,  0.2136, -0.2878, -0.1288,  0.2509,  0.2339, -0.1292,\n",
      "          -0.2721,  0.1440,  0.2258, -0.3238,  0.0934, -0.2011, -0.2296,\n",
      "           0.6250,  0.0279,  0.0173, -0.5368, -0.1776,  0.6148,  0.0453,\n",
      "           0.0498]],\n",
      "\n",
      "        [[ 0.0262,  0.2863, -0.2135, -0.4048, -0.4895,  0.1955,  0.1607,\n",
      "          -0.1380,  0.2809,  0.6214,  0.2664, -0.1797, -0.1931,  0.3835,\n",
      "          -0.1778, -0.6647,  0.6035,  0.4222, -0.4434, -0.2769,  0.2101,\n",
      "          -0.3034,  0.1175,  0.3299,  0.5028,  0.0623, -0.0483, -0.2342,\n",
      "          -0.0350, -0.0405,  0.1880,  0.1140, -0.0865, -0.1154,  0.5822,\n",
      "           0.1927,  0.5881,  0.0999,  0.5671,  0.2896, -0.1046, -0.4286,\n",
      "           0.2024,  0.0155, -0.3950,  0.0825,  0.4484,  0.5674, -0.0081,\n",
      "          -0.2441,  0.4166,  0.4275, -0.5011,  0.0629, -0.3370, -0.6630,\n",
      "           0.3031, -0.2522, -0.0651, -0.5671,  0.3605,  0.2913, -0.0012,\n",
      "           0.1854]],\n",
      "\n",
      "        [[ 0.2215,  0.0513, -0.3868, -0.1176, -0.4511,  0.1650,  0.0075,\n",
      "          -0.2391,  0.4005,  0.2453,  0.2631, -0.2715, -0.3897,  0.6398,\n",
      "          -0.1756, -0.3466,  0.5338,  0.3771, -0.5514, -0.1531,  0.4174,\n",
      "          -0.5475,  0.3129,  0.5752,  0.3860,  0.0771, -0.3913, -0.4659,\n",
      "          -0.2482, -0.0969,  0.0913,  0.3688, -0.0645, -0.1992,  0.3343,\n",
      "           0.5153,  0.3589,  0.6296,  0.2363,  0.4988, -0.0026, -0.2148,\n",
      "           0.3988,  0.1430, -0.5451,  0.4205,  0.8156,  0.3719,  0.2611,\n",
      "          -0.3152,  0.0734,  0.4721, -0.6682,  0.5250, -0.6044, -0.4403,\n",
      "           0.0397, -0.4152, -0.5552, -0.5359,  0.1608,  0.0959, -0.0967,\n",
      "           0.1602]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.2448,  0.4606, -0.3512, -0.2776, -0.0434,  0.0348,  0.4456,\n",
      "          -0.0256,  0.4325,  0.4343,  0.3818, -0.2602, -0.3510,  0.5047,\n",
      "          -0.4884, -0.3547,  0.5320,  0.2540, -0.6257, -0.4063, -0.1158,\n",
      "           0.0107,  0.3030,  0.5571,  0.7108, -0.0145,  0.0552, -0.3626,\n",
      "          -0.0470,  0.0906,  0.0396, -0.1472, -0.2058, -0.1609,  0.4733,\n",
      "           0.3764,  0.5116,  0.5791,  0.5381,  0.1261, -0.5747, -0.0529,\n",
      "           0.3070,  0.2244, -0.3123, -0.1145,  0.2859,  0.2581, -0.1285,\n",
      "          -0.2901,  0.1627,  0.2583, -0.3478,  0.1155, -0.2111, -0.2429,\n",
      "           0.6438,  0.0107,  0.0074, -0.5561, -0.1633,  0.6377,  0.0402,\n",
      "           0.0566]],\n",
      "\n",
      "        [[ 0.0322,  0.3203, -0.2247, -0.4234, -0.5038,  0.2174,  0.1758,\n",
      "          -0.1462,  0.3067,  0.6417,  0.2892, -0.1911, -0.2145,  0.4014,\n",
      "          -0.1881, -0.6863,  0.6222,  0.4429, -0.4596, -0.2990,  0.2212,\n",
      "          -0.3194,  0.1298,  0.3591,  0.5306,  0.0757, -0.0538, -0.2553,\n",
      "          -0.0415, -0.0540,  0.1973,  0.1257, -0.1025, -0.1262,  0.6012,\n",
      "           0.2118,  0.6061,  0.1153,  0.5964,  0.3139, -0.1208, -0.4402,\n",
      "           0.2132,  0.0170, -0.4236,  0.1035,  0.4710,  0.5823, -0.0030,\n",
      "          -0.2657,  0.4292,  0.4485, -0.5267,  0.0730, -0.3564, -0.6799,\n",
      "           0.3265, -0.2812, -0.0756, -0.5872,  0.3802,  0.3128, -0.0060,\n",
      "           0.2048]],\n",
      "\n",
      "        [[ 0.2361,  0.0599, -0.4100, -0.1255, -0.4734,  0.1850,  0.0130,\n",
      "          -0.2553,  0.4275,  0.2782,  0.2879, -0.2936, -0.4082,  0.6600,\n",
      "          -0.1900, -0.3642,  0.5578,  0.3988, -0.5724, -0.1708,  0.4426,\n",
      "          -0.5702,  0.3404,  0.6032,  0.4109,  0.0985, -0.4114, -0.4917,\n",
      "          -0.2700, -0.1027,  0.1074,  0.3894, -0.0729, -0.2177,  0.3509,\n",
      "           0.5483,  0.3716,  0.6532,  0.2601,  0.5167, -0.0046, -0.2322,\n",
      "           0.4195,  0.1447, -0.5683,  0.4535,  0.8257,  0.3878,  0.2771,\n",
      "          -0.3373,  0.0793,  0.4833, -0.6890,  0.5466, -0.6241, -0.4668,\n",
      "           0.0545, -0.4459, -0.5720, -0.5521,  0.1777,  0.1043, -0.1031,\n",
      "           0.1701]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.2639,  0.4865, -0.3666, -0.2919, -0.0498,  0.0391,  0.4641,\n",
      "          -0.0300,  0.4551,  0.4607,  0.4094, -0.2707, -0.3706,  0.5197,\n",
      "          -0.5094, -0.3682,  0.5542,  0.2648, -0.6375, -0.4271, -0.1204,\n",
      "          -0.0156,  0.3229,  0.5740,  0.7264, -0.0120,  0.0539, -0.3768,\n",
      "          -0.0533,  0.0815,  0.0404, -0.1448, -0.2255, -0.1625,  0.4883,\n",
      "           0.3949,  0.5338,  0.6006,  0.5642,  0.1360, -0.5969, -0.0657,\n",
      "           0.3302,  0.2372, -0.3389, -0.0989,  0.3222,  0.2823, -0.1278,\n",
      "          -0.3093,  0.1834,  0.2926, -0.3727,  0.1398, -0.2220, -0.2571,\n",
      "           0.6630, -0.0077, -0.0036, -0.5753, -0.1478,  0.6596,  0.0331,\n",
      "           0.0641]],\n",
      "\n",
      "        [[ 0.0385,  0.3558, -0.2367, -0.4416, -0.5178,  0.2391,  0.1921,\n",
      "          -0.1549,  0.3334,  0.6609,  0.3125, -0.2029, -0.2366,  0.4194,\n",
      "          -0.1989, -0.7064,  0.6407,  0.4640, -0.4757, -0.3214,  0.2351,\n",
      "          -0.3361,  0.1428,  0.3889,  0.5584,  0.0897, -0.0596, -0.2769,\n",
      "          -0.0488, -0.0660,  0.2093,  0.1378, -0.1195, -0.1384,  0.6202,\n",
      "           0.2311,  0.6236,  0.1317,  0.6253,  0.3391, -0.1381, -0.4531,\n",
      "           0.2245,  0.0195, -0.4530,  0.1265,  0.4942,  0.5974,  0.0027,\n",
      "          -0.2886,  0.4441,  0.4701, -0.5515,  0.0840, -0.3763, -0.6969,\n",
      "           0.3507, -0.3104, -0.0871, -0.6071,  0.4007,  0.3347, -0.0123,\n",
      "           0.2252]],\n",
      "\n",
      "        [[ 0.2517,  0.0695, -0.4335, -0.1335, -0.4953,  0.2063,  0.0189,\n",
      "          -0.2725,  0.4548,  0.3112,  0.3142, -0.3164, -0.4267,  0.6792,\n",
      "          -0.2049, -0.3824,  0.5815,  0.4209, -0.5928, -0.1896,  0.4694,\n",
      "          -0.5929,  0.3683,  0.6306,  0.4368,  0.1218, -0.4313, -0.5182,\n",
      "          -0.2927, -0.1084,  0.1256,  0.4101, -0.0817, -0.2380,  0.3681,\n",
      "           0.5800,  0.3841,  0.6755,  0.2851,  0.5343, -0.0067, -0.2502,\n",
      "           0.4404,  0.1504, -0.5905,  0.4863,  0.8351,  0.4039,  0.2943,\n",
      "          -0.3597,  0.0871,  0.4942, -0.7091,  0.5681, -0.6433, -0.4935,\n",
      "           0.0698, -0.4765, -0.5879, -0.5686,  0.1951,  0.1128, -0.1107,\n",
      "           0.1817]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.2838,  0.5120, -0.3826, -0.3061, -0.0571,  0.0436,  0.4827,\n",
      "          -0.0350,  0.4781,  0.4873,  0.4359, -0.2815, -0.3900,  0.5349,\n",
      "          -0.5307, -0.3823,  0.5768,  0.2767, -0.6495, -0.4485, -0.1234,\n",
      "          -0.0430,  0.3439,  0.5911,  0.7418, -0.0096,  0.0525, -0.3914,\n",
      "          -0.0600,  0.0738,  0.0417, -0.1425, -0.2469, -0.1650,  0.5039,\n",
      "           0.4136,  0.5566,  0.6223,  0.5908,  0.1466, -0.6188, -0.0806,\n",
      "           0.3543,  0.2516, -0.3675, -0.0817,  0.3591,  0.3061, -0.1271,\n",
      "          -0.3296,  0.2059,  0.3285, -0.3982,  0.1663, -0.2340, -0.2723,\n",
      "           0.6823, -0.0270, -0.0159, -0.5942, -0.1310,  0.6807,  0.0243,\n",
      "           0.0721]],\n",
      "\n",
      "        [[ 0.0452,  0.3924, -0.2494, -0.4595, -0.5314,  0.2606,  0.2096,\n",
      "          -0.1641,  0.3610,  0.6792,  0.3360, -0.2149, -0.2597,  0.4372,\n",
      "          -0.2102, -0.7251,  0.6591,  0.4855, -0.4917, -0.3440,  0.2517,\n",
      "          -0.3535,  0.1565,  0.4190,  0.5859,  0.1043, -0.0659, -0.2989,\n",
      "          -0.0569, -0.0764,  0.2237,  0.1502, -0.1375, -0.1518,  0.6392,\n",
      "           0.2503,  0.6406,  0.1491,  0.6535,  0.3649, -0.1565, -0.4672,\n",
      "           0.2362,  0.0229, -0.4827,  0.1516,  0.5178,  0.6127,  0.0090,\n",
      "          -0.3125,  0.4609,  0.4922, -0.5753,  0.0960, -0.3966, -0.7139,\n",
      "           0.3754, -0.3395, -0.0999, -0.6267,  0.4216,  0.3567, -0.0201,\n",
      "           0.2466]],\n",
      "\n",
      "        [[ 0.2681,  0.0802, -0.4572, -0.1415, -0.5170,  0.2288,  0.0251,\n",
      "          -0.2906,  0.4822,  0.3439,  0.3417, -0.3399, -0.4453,  0.6972,\n",
      "          -0.2202, -0.4010,  0.6049,  0.4434, -0.6127, -0.2094,  0.4974,\n",
      "          -0.6155,  0.3967,  0.6574,  0.4636,  0.1474, -0.4509, -0.5450,\n",
      "          -0.3165, -0.1141,  0.1460,  0.4309, -0.0910, -0.2600,  0.3857,\n",
      "           0.6102,  0.3963,  0.6964,  0.3111,  0.5516, -0.0091, -0.2689,\n",
      "           0.4613,  0.1593, -0.6119,  0.5188,  0.8441,  0.4203,  0.3128,\n",
      "          -0.3825,  0.0966,  0.5047, -0.7283,  0.5893, -0.6618, -0.5203,\n",
      "           0.0859, -0.5068, -0.6031, -0.5854,  0.2131,  0.1214, -0.1195,\n",
      "           0.1950]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.3046,  0.5371, -0.3990, -0.3202, -0.0652,  0.0483,  0.5014,\n",
      "          -0.0405,  0.5017,  0.5140,  0.4613, -0.2928, -0.4093,  0.5502,\n",
      "          -0.5520, -0.3971,  0.5998,  0.2898, -0.6617, -0.4705, -0.1245,\n",
      "          -0.0718,  0.3661,  0.6083,  0.7570, -0.0072,  0.0510, -0.4066,\n",
      "          -0.0670,  0.0678,  0.0435, -0.1403, -0.2701, -0.1685,  0.5201,\n",
      "           0.4325,  0.5797,  0.6440,  0.6176,  0.1579, -0.6403, -0.0975,\n",
      "           0.3791,  0.2676, -0.3978, -0.0626,  0.3959,  0.3295, -0.1262,\n",
      "          -0.3511,  0.2301,  0.3657, -0.4243,  0.1951, -0.2470, -0.2884,\n",
      "           0.7017, -0.0473, -0.0298, -0.6128, -0.1129,  0.7008,  0.0140,\n",
      "           0.0809]],\n",
      "\n",
      "        [[ 0.0523,  0.4298, -0.2631, -0.4769, -0.5449,  0.2818,  0.2284,\n",
      "          -0.1738,  0.3893,  0.6965,  0.3596, -0.2272, -0.2835,  0.4549,\n",
      "          -0.2221, -0.7423,  0.6772,  0.5073, -0.5074, -0.3667,  0.2708,\n",
      "          -0.3717,  0.1710,  0.4491,  0.6128,  0.1194, -0.0726, -0.3213,\n",
      "          -0.0659, -0.0850,  0.2403,  0.1629, -0.1566, -0.1664,  0.6581,\n",
      "           0.2695,  0.6570,  0.1675,  0.6808,  0.3912, -0.1762, -0.4823,\n",
      "           0.2484,  0.0270, -0.5125,  0.1789,  0.5416,  0.6280,  0.0161,\n",
      "          -0.3375,  0.4794,  0.5146, -0.5981,  0.1091, -0.4172, -0.7307,\n",
      "           0.4006, -0.3680, -0.1141, -0.6458,  0.4429,  0.3789, -0.0291,\n",
      "           0.2688]],\n",
      "\n",
      "        [[ 0.2855,  0.0923, -0.4810, -0.1495, -0.5385,  0.2527,  0.0317,\n",
      "          -0.3095,  0.5099,  0.3760,  0.3705, -0.3639, -0.4641,  0.7143,\n",
      "          -0.2357, -0.4202,  0.6276,  0.4661, -0.6320, -0.2300,  0.5262,\n",
      "          -0.6380,  0.4252,  0.6832,  0.4911,  0.1752, -0.4703, -0.5721,\n",
      "          -0.3413, -0.1195,  0.1686,  0.4518, -0.1007, -0.2834,  0.4039,\n",
      "           0.6387,  0.4083,  0.7159,  0.3381,  0.5687, -0.0119, -0.2883,\n",
      "           0.4823,  0.1709, -0.6324,  0.5507,  0.8525,  0.4368,  0.3325,\n",
      "          -0.4054,  0.1079,  0.5151, -0.7467,  0.6102, -0.6796, -0.5470,\n",
      "           0.1029, -0.5365, -0.6174, -0.6024,  0.2316,  0.1303, -0.1297,\n",
      "           0.2100]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.3261,  0.5616, -0.4160, -0.3342, -0.0744,  0.0532,  0.5200,\n",
      "          -0.0467,  0.5256,  0.5406,  0.4855, -0.3047, -0.4286,  0.5656,\n",
      "          -0.5735, -0.4125,  0.6230,  0.3043, -0.6740, -0.4929, -0.1236,\n",
      "          -0.1020,  0.3893,  0.6257,  0.7719, -0.0048,  0.0494, -0.4222,\n",
      "          -0.0743,  0.0633,  0.0458, -0.1382, -0.2949, -0.1729,  0.5368,\n",
      "           0.4514,  0.6031,  0.6658,  0.6443,  0.1698, -0.6613, -0.1165,\n",
      "           0.4046,  0.2852, -0.4297, -0.0415,  0.4322,  0.3521, -0.1253,\n",
      "          -0.3736,  0.2558,  0.4038, -0.4508,  0.2262, -0.2610, -0.3056,\n",
      "           0.7208, -0.0684, -0.0454, -0.6311, -0.0934,  0.7198,  0.0023,\n",
      "           0.0905]],\n",
      "\n",
      "        [[ 0.0599,  0.4676, -0.2776, -0.4937, -0.5582,  0.3028,  0.2485,\n",
      "          -0.1841,  0.4183,  0.7128,  0.3830, -0.2399, -0.3080,  0.4722,\n",
      "          -0.2346, -0.7582,  0.6949,  0.5295, -0.5230, -0.3895,  0.2919,\n",
      "          -0.3908,  0.1863,  0.4789,  0.6389,  0.1350, -0.0796, -0.3439,\n",
      "          -0.0759, -0.0919,  0.2590,  0.1760, -0.1766, -0.1822,  0.6767,\n",
      "           0.2884,  0.6729,  0.1870,  0.7068,  0.4179, -0.1971, -0.4984,\n",
      "           0.2610,  0.0318, -0.5420,  0.2085,  0.5655,  0.6434,  0.0238,\n",
      "          -0.3633,  0.4992,  0.5372, -0.6199,  0.1233, -0.4381, -0.7473,\n",
      "           0.4260, -0.3956, -0.1297, -0.6645,  0.4645,  0.4012, -0.0392,\n",
      "           0.2918]],\n",
      "\n",
      "        [[ 0.3039,  0.1059, -0.5046, -0.1577, -0.5598,  0.2779,  0.0387,\n",
      "          -0.3293,  0.5375,  0.4072,  0.4002, -0.3884, -0.4829,  0.7304,\n",
      "          -0.2513, -0.4397,  0.6497,  0.4890, -0.6505, -0.2513,  0.5552,\n",
      "          -0.6603,  0.4540,  0.7080,  0.5192,  0.2053, -0.4893, -0.5991,\n",
      "          -0.3672, -0.1250,  0.1934,  0.4725, -0.1109, -0.3080,  0.4226,\n",
      "           0.6656,  0.4202,  0.7341,  0.3659,  0.5855, -0.0149, -0.3084,\n",
      "           0.5033,  0.1847, -0.6520,  0.5818,  0.8603,  0.4536,  0.3534,\n",
      "          -0.4285,  0.1209,  0.5253, -0.7643,  0.6306, -0.6966, -0.5734,\n",
      "           0.1210, -0.5654, -0.6310, -0.6197,  0.2505,  0.1393, -0.1413,\n",
      "           0.2268]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.3485,  0.5854, -0.4333, -0.3482, -0.0846,  0.0583,  0.5386,\n",
      "          -0.0536,  0.5497,  0.5670,  0.5085, -0.3172, -0.4478,  0.5811,\n",
      "          -0.5949, -0.4285,  0.6462,  0.3199, -0.6863, -0.5157, -0.1207,\n",
      "          -0.1339,  0.4136,  0.6431,  0.7862, -0.0023,  0.0478, -0.4382,\n",
      "          -0.0819,  0.0603,  0.0485, -0.1362, -0.3211, -0.1782,  0.5541,\n",
      "           0.4703,  0.6264,  0.6873,  0.6706,  0.1825, -0.6817, -0.1377,\n",
      "           0.4305,  0.3042, -0.4626, -0.0181,  0.4673,  0.3741, -0.1242,\n",
      "          -0.3970,  0.2827,  0.4423, -0.4773,  0.2593, -0.2761, -0.3239,\n",
      "           0.7396, -0.0902, -0.0629, -0.6490, -0.0723,  0.7378, -0.0107,\n",
      "           0.1011]],\n",
      "\n",
      "        [[ 0.0682,  0.5053, -0.2929, -0.5097, -0.5714,  0.3236,  0.2700,\n",
      "          -0.1949,  0.4479,  0.7278,  0.4061, -0.2529, -0.3331,  0.4889,\n",
      "          -0.2478, -0.7730,  0.7122,  0.5519, -0.5383, -0.4123,  0.3145,\n",
      "          -0.4108,  0.2025,  0.5082,  0.6641,  0.1509, -0.0871, -0.3663,\n",
      "          -0.0869, -0.0972,  0.2796,  0.1894, -0.1975, -0.1993,  0.6950,\n",
      "           0.3071,  0.6882,  0.2075,  0.7315,  0.4447, -0.2193, -0.5153,\n",
      "           0.2742,  0.0373, -0.5708,  0.2403,  0.5893,  0.6586,  0.0323,\n",
      "          -0.3899,  0.5203,  0.5599, -0.6406,  0.1387, -0.4592, -0.7634,\n",
      "           0.4515, -0.4220, -0.1468, -0.6827,  0.4863,  0.4235, -0.0504,\n",
      "           0.3157]],\n",
      "\n",
      "        [[ 0.3233,  0.1213, -0.5280, -0.1659, -0.5809,  0.3043,  0.0462,\n",
      "          -0.3498,  0.5651,  0.4371,  0.4307, -0.4131, -0.5020,  0.7457,\n",
      "          -0.2670, -0.4595,  0.6710,  0.5118, -0.6682, -0.2731,  0.5838,\n",
      "          -0.6823,  0.4829,  0.7314,  0.5477,  0.2374, -0.5078, -0.6258,\n",
      "          -0.3941, -0.1304,  0.2205,  0.4931, -0.1214, -0.3335,  0.4419,\n",
      "           0.6908,  0.4319,  0.7510,  0.3944,  0.6020, -0.0183, -0.3291,\n",
      "           0.5243,  0.2005, -0.6708,  0.6120,  0.8677,  0.4705,  0.3755,\n",
      "          -0.4516,  0.1356,  0.5354, -0.7810,  0.6505, -0.7128, -0.5994,\n",
      "           0.1403, -0.5931, -0.6438, -0.6371,  0.2698,  0.1486, -0.1542,\n",
      "           0.2455]]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "t\n",
      "tensor([18])\n",
      "s\n",
      "{'start': tensor(17), 'end': tensor(20)}\n",
      "target\n",
      "tensor([[[ 0.3716,  0.6086, -0.4511, -0.3621, -0.0961,  0.0637,  0.5571,\n",
      "          -0.0614,  0.5738,  0.5930,  0.5304, -0.3303, -0.4670,  0.5964,\n",
      "          -0.6162, -0.4451,  0.6692,  0.3369, -0.6987, -0.5386, -0.1157,\n",
      "          -0.1675,  0.4387,  0.6604,  0.8000,  0.0003,  0.0462, -0.4544,\n",
      "          -0.0898,  0.0585,  0.0517, -0.1343, -0.3487, -0.1842,  0.5720,\n",
      "           0.4892,  0.6496,  0.7086,  0.6967,  0.1960, -0.7015, -0.1606,\n",
      "           0.4570,  0.3241, -0.4960,  0.0091,  0.5009,  0.3957, -0.1230,\n",
      "          -0.4213,  0.3111,  0.4822, -0.5027,  0.2947, -0.2922, -0.3429,\n",
      "           0.7579, -0.1148, -0.0822, -0.6668, -0.0497,  0.7549, -0.0246,\n",
      "           0.1128]],\n",
      "\n",
      "        [[ 0.0770,  0.5423, -0.3091, -0.5251, -0.5846,  0.3444,  0.2926,\n",
      "          -0.2065,  0.4778,  0.7417,  0.4287, -0.2663, -0.3588,  0.5049,\n",
      "          -0.2617, -0.7866,  0.7290,  0.5744, -0.5534, -0.4350,  0.3380,\n",
      "          -0.4317,  0.2195,  0.5366,  0.6880,  0.1669, -0.0950, -0.3885,\n",
      "          -0.0989, -0.1010,  0.3020,  0.2032, -0.2191, -0.2171,  0.7132,\n",
      "           0.3255,  0.7029,  0.2291,  0.7556,  0.4717, -0.2425, -0.5325,\n",
      "           0.2880,  0.0431, -0.5986,  0.2763,  0.6129,  0.6742,  0.0416,\n",
      "          -0.4176,  0.5434,  0.5832, -0.6596,  0.1554, -0.4809, -0.7787,\n",
      "           0.4767, -0.4493, -0.1653, -0.7009,  0.5082,  0.4462, -0.0624,\n",
      "           0.3403]],\n",
      "\n",
      "        [[ 0.3436,  0.1385, -0.5510, -0.1743, -0.6017,  0.3318,  0.0543,\n",
      "          -0.3712,  0.5924,  0.4657,  0.4615, -0.4380, -0.5213,  0.7602,\n",
      "          -0.2826, -0.4795,  0.6914,  0.5346, -0.6851, -0.2953,  0.6118,\n",
      "          -0.7039,  0.5117,  0.7533,  0.5763,  0.2715, -0.5260, -0.6519,\n",
      "          -0.4218, -0.1358,  0.2499,  0.5133, -0.1323, -0.3587,  0.4624,\n",
      "           0.7145,  0.4439,  0.7666,  0.4251,  0.6181, -0.0219, -0.3498,\n",
      "           0.5460,  0.2169, -0.6890,  0.6434,  0.8747,  0.4885,  0.3982,\n",
      "          -0.4755,  0.1536,  0.5483, -0.7962,  0.6702, -0.7289, -0.6238,\n",
      "           0.1603, -0.6235, -0.6558, -0.6554,  0.2892,  0.1588, -0.1681,\n",
      "           0.2661]]], device='cuda:0')\n",
      "after\n",
      "tensor([[-3.4579, -6.8669, -6.2388, -6.5194, -6.4636, -6.3589, -6.9559, -6.8899,\n",
      "         -6.6114, -7.2741, -6.5885, -6.7083, -6.4190, -6.4909, -6.7619, -7.3434,\n",
      "         -6.5650, -6.8917, -6.2648, -6.4191, -7.2245, -6.9478, -7.0565, -6.4610,\n",
      "         -7.2282, -6.2562, -6.8012, -5.9088, -6.5118, -7.0778, -6.5587, -6.5996,\n",
      "         -6.2811, -7.1894, -6.9613, -6.5258, -6.1714, -7.0288, -6.7181, -6.5791,\n",
      "         -6.6936, -6.9973, -6.3854, -6.4671, -6.6154, -6.0722, -6.7447, -6.2600,\n",
      "         -6.6853, -6.1797, -6.8301, -6.8849, -6.5726, -5.6046, -6.3026, -6.9046,\n",
      "         -6.6905, -6.9421, -6.5552, -6.2815, -6.8952, -7.4759, -6.1229, -6.9388,\n",
      "         -7.1006, -5.9629, -6.9863, -5.8814, -7.4063, -7.5071, -6.9240, -7.2189,\n",
      "         -7.2069, -6.8138, -6.2328, -6.5600, -5.8293, -6.7822, -6.1055, -6.5378,\n",
      "         -6.3831, -7.0112, -6.7817, -6.8110, -6.8098, -6.7648, -5.8064, -6.2574,\n",
      "         -6.4474, -6.1460, -6.4444, -7.2308, -7.5825, -6.7415, -6.4915, -6.8227,\n",
      "         -7.0761, -7.0767, -6.5088, -6.4096, -6.7306, -5.8414, -6.8981, -5.7713,\n",
      "         -7.0819, -7.1284, -6.8908, -6.5739, -6.0031, -6.6995, -6.8012, -6.7231,\n",
      "         -6.2131, -7.0145, -7.1937, -5.8010, -6.8629, -5.9257, -6.4483, -6.6360,\n",
      "         -6.7986, -6.7284, -6.6163, -6.7441, -6.3644, -6.4520, -6.8038, -7.6874,\n",
      "         -6.1377, -6.7568, -6.9293, -6.6865, -5.6322, -6.0869, -7.0449, -6.6477,\n",
      "         -6.5591, -6.6793, -7.3978, -6.2750, -6.7468, -6.9879, -6.6351, -7.1335,\n",
      "         -5.8209, -6.9550, -6.2791, -6.7719, -6.1873, -6.4334, -6.3043, -6.8440,\n",
      "         -6.5982, -7.3299, -6.7378, -6.5409, -5.7588, -6.1384, -6.6556, -6.6144,\n",
      "         -6.6318, -7.2143, -6.0076, -6.4422, -6.7270, -6.6536, -5.9688, -6.2067,\n",
      "         -6.9391, -6.5297, -6.6978, -6.0620, -6.6731, -5.9319, -6.7529, -6.5328,\n",
      "         -7.2731, -6.5345, -6.5186, -6.8162, -7.0033, -6.7390, -6.1907, -6.6563,\n",
      "         -6.3566, -6.1301, -5.7744, -6.6171, -6.4154, -6.4607, -6.5597, -7.0970,\n",
      "         -6.3073, -6.5633, -6.6342, -6.7556, -6.4603, -6.7093, -6.6606, -6.8460,\n",
      "         -6.9399, -6.5163, -6.0529, -5.8534, -6.6206, -6.5363, -6.4050, -6.9932,\n",
      "         -6.5304, -6.9009, -5.8590, -6.8668, -6.8259, -7.1813, -6.7549, -6.9369,\n",
      "         -5.7316, -6.8299, -6.6156, -6.7021, -5.7944, -6.0707, -6.3962, -6.9931,\n",
      "         -5.3087, -6.9047, -6.4584, -6.6965, -6.8327, -6.4335, -7.9816, -6.4183,\n",
      "         -6.3986, -6.2052, -6.3083, -6.1600, -6.1989, -6.5234, -6.0847, -7.0209,\n",
      "         -5.9795, -6.0727, -6.8454, -6.5907, -7.2047, -6.6813, -6.7390, -6.8766,\n",
      "         -6.7002, -7.0175, -6.9247, -6.5096, -6.8866, -6.7851, -6.3031, -6.7798,\n",
      "         -6.2714, -6.8123, -6.7555, -6.3006, -6.2690, -6.7388, -7.1762, -7.0323,\n",
      "         -6.2851, -6.4267, -7.4014, -6.1303, -6.5817, -6.7474, -6.5145, -6.8811,\n",
      "         -6.1431, -7.1813, -6.5685, -6.4664, -6.9901, -7.2218, -6.1640, -6.9851,\n",
      "         -7.3603, -6.6964, -6.2409, -7.0345, -6.8340, -6.6466, -7.0071, -6.2301,\n",
      "         -6.7340, -7.1117, -5.5863, -6.3277, -6.7363, -6.3431, -6.5993, -6.5664,\n",
      "         -6.8764, -6.5282, -6.5343, -6.0933, -6.9787, -6.2571, -6.5472, -6.9930,\n",
      "         -6.6367, -6.9401, -5.8178, -6.5338, -6.6098, -6.6142, -6.6467, -6.1400,\n",
      "         -6.5934, -6.7119, -7.1869, -6.8342, -6.6104, -6.5501, -5.6951, -6.2048,\n",
      "         -6.7886, -5.8557, -6.3430, -6.0662, -7.2221, -6.6315, -6.9844, -7.1350,\n",
      "         -6.2263, -6.7726, -6.4706, -6.9739, -6.9161, -5.9148, -6.9318, -6.7219,\n",
      "         -6.4228, -6.7417, -6.3047, -6.2546, -7.1333, -6.6263, -6.3119, -6.6320,\n",
      "         -6.5988, -6.1620, -7.0968, -6.2559, -6.5486, -6.2842, -6.8770, -6.3356,\n",
      "         -6.8732, -6.7592, -6.4739, -6.2006, -7.1585, -6.0437, -6.3122, -5.8297,\n",
      "         -6.5283, -6.5365, -7.1207, -6.3386, -6.7351, -6.7698, -6.8394, -7.0717,\n",
      "         -6.8549, -6.2763, -6.8709, -5.7361, -6.3771, -7.0198, -6.4017, -7.0260,\n",
      "         -7.1842, -7.1534, -6.4279, -6.8245, -6.5918, -6.8950, -6.5572, -5.9728,\n",
      "         -6.0213, -6.9784, -6.7304, -6.5115, -6.8240, -6.1274, -7.0163, -6.1568,\n",
      "         -6.0784, -6.7199, -7.1305, -6.3033, -6.7744, -6.3174, -6.3033, -7.5562,\n",
      "         -6.3818, -6.6466, -6.4649, -7.0565, -6.7896, -6.7457, -7.1887, -7.0525,\n",
      "         -6.0802, -7.0260, -6.6831, -7.1137, -7.0438, -6.1423, -6.9998, -6.4046,\n",
      "         -5.2848, -6.0161, -5.9947, -7.0936, -6.5027, -6.7912, -5.8732, -6.4758,\n",
      "         -6.2614, -6.0648, -6.3479, -7.0349, -6.0990, -5.9470, -7.0277, -6.4884,\n",
      "         -5.8952, -6.9648, -7.1141, -7.1709, -6.6257, -6.7549, -5.8878, -5.9050,\n",
      "         -5.8486, -6.8556, -6.2518, -6.4805, -6.3110, -6.8902, -6.9034, -6.6003,\n",
      "         -6.7370, -6.6039, -6.9039, -6.5425, -6.1541, -6.0588, -6.4355, -6.5411,\n",
      "         -6.2220, -6.4775, -6.3723, -6.4080, -5.9770, -5.9672, -6.6817, -6.2182,\n",
      "         -7.2127, -6.9170, -7.2015, -6.2763, -6.6639, -6.7313, -6.3557, -6.9252,\n",
      "         -6.5546, -6.2682, -6.5560, -7.6740, -6.8211, -6.6703, -6.6486, -6.3489,\n",
      "         -6.9268, -6.4594, -6.3308, -6.7833, -5.9982, -6.7225, -6.5426, -6.5834,\n",
      "         -6.2358, -6.7397, -6.4401, -6.3621, -6.6018, -6.2232, -6.1552, -6.0125,\n",
      "         -6.3001, -7.2226, -6.4605, -6.2892, -6.7308, -6.2433, -6.7807, -6.0333,\n",
      "         -6.2524, -6.8030, -6.3804, -6.3394, -6.3771, -7.1461, -6.4512, -7.0442,\n",
      "         -7.4190, -6.2010, -7.0564, -6.4927, -6.5732, -6.8876, -6.2480, -6.4570,\n",
      "         -6.7048, -6.7998, -7.0895, -6.7949, -6.5818, -6.2829, -6.4088, -6.3320,\n",
      "         -6.6673, -6.1076, -7.2056, -6.6048, -6.8361, -6.7739, -6.2762, -6.7964,\n",
      "         -6.3495, -6.0487, -6.9722, -7.1751, -6.1851, -7.0828, -6.6359, -6.7225,\n",
      "         -6.5522, -6.2638, -7.0274, -6.3185, -6.4021, -6.6493, -6.3256, -6.6938,\n",
      "         -6.4955, -6.2797, -6.4376, -6.7328, -6.3142, -6.9935, -6.2861, -6.5315,\n",
      "         -6.6901, -6.0218, -6.6184, -6.6759, -7.2238, -6.7973, -6.3307, -7.0841,\n",
      "         -6.5121, -6.2316, -6.2983, -7.4538, -6.0610, -7.2227, -6.6712, -6.8307,\n",
      "         -6.3230, -5.7737, -6.2898, -7.0300, -6.9079, -7.1686, -6.3435, -7.1130,\n",
      "         -6.6448, -6.8610, -6.7812, -7.4207, -6.7728, -7.0502, -6.7977, -6.4452,\n",
      "         -6.1976, -6.4565, -6.6780, -6.3305, -6.3924, -6.9220, -6.2724, -5.5933,\n",
      "         -7.1894, -6.1684, -6.5761, -7.1630, -6.0815, -6.6944, -6.6513, -6.8690,\n",
      "         -7.0287, -6.6135, -6.6706, -7.1296, -6.4654, -6.6772, -6.7210, -7.0880,\n",
      "         -6.9725, -6.4759, -6.2732, -6.4677, -7.1284, -7.2481, -7.2028, -5.9703,\n",
      "         -6.7521, -6.5545, -5.9139, -7.4181, -6.8259, -5.6201, -6.3463, -7.1563,\n",
      "         -6.3641, -6.5087, -6.1761, -6.3448, -6.9055, -6.3099, -6.4732, -6.8392,\n",
      "         -6.7078, -6.6198, -5.6201, -6.4050, -7.1594, -6.7322, -6.6073, -6.5186,\n",
      "         -5.9174, -6.5988, -6.6422, -6.5081, -6.6288, -6.7377, -7.1530, -7.2491,\n",
      "         -6.8804]], device='cuda:0')\n",
      "\n",
      "\n",
      "your model is saved: ./model/lstm180731\n",
      "time spent: 1507.6531183719635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type LSTMTagger. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(len(word_to_ix), len(frame_to_ix))\n",
    "if usingGPU:\n",
    "    model.cuda()\n",
    "else:\n",
    "    pass\n",
    "\n",
    "learning_rate = 0.001\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(training_data)\n",
    "# training_data = training_data[:100]\n",
    "# total_step = len(training_data)\n",
    "# NUM_EPOCHS = 3\n",
    "# EMBEDDING_DIM = 6\n",
    "# HIDDEN_DIM = 6\n",
    "\n",
    "# seq_data = gen_sequence_data(training_data)\n",
    "# batch_data = torch.utils.data.DataLoader(seq_data, batch_size=batch_size)\n",
    "# total_step = len(batch_data)\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     for step, (sent, frame, targetposition) in enumerate(batch_data):\n",
    "#         model.zero_grad()\n",
    "#         model.hidden_lstm_1 = model.init_hidden_lstm_1()\n",
    "#         model.hidden_lstm_2 = model.init_hidden_lstm_2()\n",
    "        \n",
    "#         tag_scores = model(sent, targetposition)\n",
    "#         loss = loss_function(tag_scores, frames)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()     \n",
    "\n",
    "#         if n % 10 == 0:\n",
    "#             print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "#                    .format(epoch+1, NUM_EPOCHS, step, total_step, loss.item()))\n",
    "#         break\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    n = 0\n",
    "    for tokens in training_data:\n",
    "        model.zero_grad()\n",
    "        model.hidden_lstm_1 = model.init_hidden_lstm_1()\n",
    "        model.hidden_lstm_2 = model.init_hidden_lstm_2()\n",
    "        \n",
    "        sentence, pos, frame = prepare_sentence(tokens)\n",
    "        targetpositions = get_targetpositions(tokens)\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        frames = prepare_frame_sequence(frame, frame_to_ix)\n",
    "#         frames = prepare_frame_vector(frame, frame_to_ix)\n",
    "\n",
    "        tag_scores = model(sentence_in, targetpositions)\n",
    "        loss = loss_function(tag_scores, frames)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        n = n+1\n",
    "\n",
    "        if n % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, NUM_EPOCHS, n, total_step, loss.item()))\n",
    "#         break\n",
    "            \n",
    "torch.save(model, model_path)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    sentence, pos, frame = prepare_sentence(training_data[0])\n",
    "    targetpositions = get_targetpositions(training_data[0])\n",
    "    inputs = prepare_sequence(sentence, word_to_ix)\n",
    "    tag_scores = model(inputs,targetpositions)\n",
    "    print('after')\n",
    "    print(tag_scores)\n",
    "    print('\\n')\n",
    "    \n",
    "print('your model is saved:', model_path)\n",
    "print('time spent:', time.time()-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
